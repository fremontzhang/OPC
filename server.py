import requests
import json
import sqlite3
import os
import mimetypes
import traceback
import datetime
import sys
import io
from flask import Flask, request, jsonify, session, send_from_directory
from flask_cors import CORS
from werkzeug.security import generate_password_hash, check_password_hash
import hashlib
import random
import time

# è®¾ç½®æ§åˆ¶å°è¾“å‡ºç¼–ç ä¸º UTF-8ï¼ˆé¿å… Windows GBK ç¼–ç é”™è¯¯ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

app = Flask(__name__)
app.secret_key = "super_secret_social_sync_key" 
CORS(app, supports_credentials=True, resources={r"/*": {"origins": "*"}}) # æè‡´å®½æ¾çš„ CORS ç­–ç•¥

# --- ä½ çš„ä¸“å±é…ç½® ---
API_KEY = "1db8d00b-13aa-4e78-85c0-17e0af6a7f95"
TEAM_ID = "e06e8cc1-454d-4555-9346-b1d2aa212ba1"
BASE_URL = "https://api.bundle.social/api/v1"
DB_PATH = "platform.db"
API_BASE = "http://127.0.0.1:5000"

from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# é…ç½®å…¨å±€ Session åŠå…¶é‡è¯•ç­–ç•¥
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[500, 502, 503, 504],
    allowed_methods=["HEAD", "GET", "OPTIONS", "POST", "PUT"]
)
adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=20, pool_maxsize=20)
http_session = requests.Session()
http_session.mount("https://", adapter)
http_session.mount("http://", adapter)

# --- é™æ€æ–‡ä»¶æœåŠ¡ ---
@app.route('/')
def serve_index():
    return send_from_directory('.', 'dashboard.html')

@app.route('/<path:path>')
def serve_static(path):
    return send_from_directory('.', path)

@app.route('/api/ping')
def ping():
    return jsonify({"status": "ok", "time": str(datetime.datetime.now())})

def request_with_proxy_fallback(method, url, **kwargs):
    """
    é€šç”¨è¯·æ±‚åŒ…è£…å™¨ï¼šå¢å¼ºç‰ˆé‡è¯•æœºåˆ¶ï¼Œåº”å¯¹ SSL å’Œç½‘ç»œæ³¢åŠ¨
    """
    # é»˜è®¤ç»™ä¸€ä¸ªåˆç†çš„è¶…æ—¶æ—¶é—´
    if 'timeout' not in kwargs: kwargs['timeout'] = (10, 300) # 10s connect, 300s read
    elif isinstance(kwargs['timeout'], (int, float)):
        kwargs['timeout'] = (10, kwargs['timeout'])

    max_retries = 3
    last_exception = None
    
    # ğŸš¨ ä¼˜åŒ–ï¼šé’ˆå¯¹ä¸Šä¼ æ“ä½œï¼Œå¦‚æœå·²ç»å¤±è´¥è¿‡ä¸€æ¬¡ï¼Œç¬¬äºŒæ¬¡å¼ºåˆ¶ä½¿ç”¨éæ± åŒ–è¿æ¥
    import requests as raw_requests
    
    # ç­–ç•¥ 1: é»˜è®¤é…ç½®é‡è¯•
    for i in range(max_retries):
        try:
            # ğŸš¨ å…³é”®ï¼šå¦‚æœ data æ˜¯æ–‡ä»¶å¯¹è±¡ï¼Œé‡è¯•å‰å¿…é¡»é‡ç½®æŒ‡é’ˆ
            if 'data' in kwargs and hasattr(kwargs['data'], 'seek'):
                kwargs['data'].seek(0)
            
            # ä½¿ç”¨å…¨å±€ Session è¯·æ±‚
            return http_session.request(method, url, **kwargs)
        except (requests.exceptions.SSLError, requests.exceptions.ChunkedEncodingError, requests.exceptions.Timeout, 
                requests.exceptions.ConnectionError) as e:
            
            error_str = str(e)
            print(f"âš ï¸ ç½‘ç»œæ³¢åŠ¨ (å°è¯• {i+1}/{max_retries}): {error_str[:150]}")
            
            # é’ˆå¯¹ç‰¹å®šé”™è¯¯ (Connection aborted / Timeout) å¢åŠ ç­‰å¾…æ—¶é—´
            if "aborted" in error_str.lower() or "timeout" in error_str.lower():
                time.sleep(i * 3 + 2) # é€’å¢ç­‰å¾… 2s, 5s, 8s
            else:
                time.sleep(1)
            
            last_exception = e
            
            # ğŸš¨ å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œæˆ–è€…é‡åˆ°ä¸¥é‡çš„è¿æ¥ä¸­æ–­ï¼Œç­–ç•¥ 2 ä¼šæ¥ç®¡
            continue
            
    # ç­–ç•¥ 2: å¼ºåˆ¶â€œå†·å¯åŠ¨â€è¿æ¥ (ç»•è¿‡æ‰€æœ‰ç¼“å­˜å’Œä»£ç†)
    print(f"âš ï¸ é»˜è®¤è·¯å¾„æ— æ³•é€è¾¾ï¼Œå¯åŠ¨â€˜å†·å¯åŠ¨â€™æ¨¡å¼ (ç¦ç”¨ä»£ç† & é‡æ–°å»ºç«‹è¿æ¥)...")
    kwargs['proxies'] = {"http": None, "https": None}
    
    # PUT è¯·æ±‚åœ¨å¤§è§†é¢‘ä¸Šä¼ æ—¶å®¹æ˜“å› ä¸º Pool é‡Œçš„æ—§è¿æ¥å¤±æ•ˆæŠ¥é”™ï¼Œè¿™é‡Œç”¨ raw_requests
    for i in range(2):
        try:
            if 'data' in kwargs and hasattr(kwargs['data'], 'seek'):
                kwargs['data'].seek(0)
            
            # ä¸ä½¿ç”¨ Sessionï¼Œä½¿ç”¨æœ€åŸå§‹çš„è¿æ¥ä»¥æ±‚æœ€é«˜ç¨³å®šæ€§
            return raw_requests.request(method, url, **kwargs)
        except Exception as e:
            print(f"âŒ å†·å¯åŠ¨å¤±è´¥ ({i+1}/2): {e}")
            last_exception = e
            time.sleep(3)
            
    raise last_exception
            
    raise last_exception

import mimetypes
import base64

def upload_to_imgbb(file, filename=None):
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°å…è´¹å›¾åºŠï¼Œè·å–å…¬å¼€URL
    ä½¿ç”¨å¤šä¸ªå…è´¹å›¾åºŠæœåŠ¡ä½œä¸ºå¤‡é€‰
    è¿”å›: (url, error_msg)
    """
    try:
        print(f"[å›¾åºŠ] å‡†å¤‡ä¸Šä¼ æ–‡ä»¶...")
        
        # è¯»å–æ–‡ä»¶æ•°æ®
        if hasattr(file, 'read'):
            file.seek(0)
            file_data = file.read()
        else:
            file_data = file
        
        print(f"[å›¾åºŠ] æ–‡ä»¶å¤§å°: {len(file_data)} bytes")
        
        # åˆ¤æ–­æ–‡ä»¶ç±»å‹
        is_video = False
        if filename:
            ext = filename.lower()
            if '.mp4' in ext or '.mov' in ext or '.avi' in ext or '.webm' in ext:
                is_video = True
                print(f"[å›¾åºŠ] æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶: {filename}")
        
        # è§†é¢‘æ–‡ä»¶ï¼šä½¿ç”¨ 0x0.st
        if is_video:
            print(f"[å›¾åºŠ] ä½¿ç”¨ 0x0.st ä¸Šä¼ è§†é¢‘...")
            try:
                files = {'file': (filename or 'video.mp4', file_data)}
                response = requests.post('https://0x0.st', files=files, timeout=60)
                
                if response.status_code == 200:
                    url = response.text.strip()
                    print(f"[å›¾åºŠ] è§†é¢‘ä¸Šä¼ æˆåŠŸ: {url}")
                    return url, None
                else:
                    return None, f"è§†é¢‘ä¸Šä¼ å¤±è´¥: HTTP {response.status_code}"
            except Exception as e:
                print(f"[å›¾åºŠ] è§†é¢‘ä¸Šä¼ å¼‚å¸¸: {e}")
                return None, f"è§†é¢‘ä¸Šä¼ é”™è¯¯: {str(e)}"
        
        # å›¾ç‰‡æ–‡ä»¶ï¼šå°è¯•å¤šä¸ªå…è´¹å›¾åºŠ
        else:
            print(f"[å›¾åºŠ] ä¸Šä¼ å›¾ç‰‡...")
            
            # æ–¹æ¡ˆ1: freeimage.host (å…è´¹ï¼Œæ— éœ€API key)
            try:
                print(f"[å›¾åºŠ] å°è¯• freeimage.host...")
                files = {'source': (filename or 'image.jpg', file_data)}
                data = {'type': 'file', 'action': 'upload'}
                
                response = requests.post(
                    'https://freeimage.host/api/1/upload',
                    files=files,
                    data=data,
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get('status_code') == 200:
                        image_url = result['image']['url']
                        print(f"[å›¾åºŠ] freeimage.host ä¸Šä¼ æˆåŠŸ: {image_url}")
                        return image_url, None
            except Exception as e:
                print(f"[å›¾åºŠ] freeimage.host å¤±è´¥: {e}")
            
            # æ–¹æ¡ˆ2: catbox.moe (æœ€å¯é )
            try:
                print(f"[å›¾åºŠ] å°è¯• catbox.moe...")
                files = {'fileToUpload': (filename or 'image.jpg', file_data)}
                data = {'reqtype': 'fileupload'}
                
                response = requests.post(
                    'https://catbox.moe/user/api.php',
                    files=files,
                    data=data,
                    timeout=30
                )
                
                if response.status_code == 200:
                    url = response.text.strip()
                    if url.startswith('https://'):
                        print(f"[å›¾åºŠ] catbox.moe ä¸Šä¼ æˆåŠŸ: {url}")
                        return url, None
            except Exception as e:
                print(f"[å›¾åºŠ] catbox.moe å¤±è´¥: {e}")
            
            return None, "æ‰€æœ‰å›¾åºŠæœåŠ¡å‡å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
                
    except Exception as e:
        print(f"[å›¾åºŠ] å¤„ç†æ–‡ä»¶å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None, f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}"

def proxy_upload_to_bundle(file, filename=None, content_type=None):
    """
    ä½¿ç”¨Bundle Socialå®˜æ–¹æ¨èçš„ä¸‰æ­¥ä¸Šä¼ æµç¨‹
    """
    try:
        # 1. ç¡®å®šæ–‡ä»¶åå’ŒMIMEç±»å‹
        if not filename:
            filename = "upload_" + str(int(datetime.datetime.now().timestamp()))
        
        # ç¡®å®šMIMEç±»å‹
        if not content_type:
            ext = filename.lower()
            if '.jpg' in ext or '.jpeg' in ext:
                content_type = 'image/jpeg'
            elif '.png' in ext:
                content_type = 'image/png'
            elif '.mp4' in ext:
                content_type = 'video/mp4'
            else:
                content_type = 'application/octet-stream'
        
        # ğŸš¨ æè‡´åŠ å›ºï¼šæ¸…æ´— MIME ç±»å‹ (è§£å†³ video/mp4;codecs=avc1 ç­‰å¯¼è‡´çš„ 400 é”™è¯¯)
        if ';' in content_type:
            content_type = content_type.split(';')[0].strip()
            
        # ğŸš¨ é’ˆå¯¹æŸäº›å¹³å°è¿”å›çš„éæ ‡å‡†ç±»å‹è¿›è¡Œçº æ­£
        if content_type == 'video/quicktime' or filename.lower().endswith('.mov'):
            content_type = 'video/mp4'
        elif content_type == 'image/jpg':
            content_type = 'image/jpeg'
        
        # å¼ºåˆ¶æ‹¦æˆªä¸åˆæ³•çš„ç±»å‹
        allowed_mimes = ['image/jpeg', 'image/jpg', 'image/png', 'video/mp4', 'application/pdf']
        if content_type not in allowed_mimes:
            if 'video' in content_type: content_type = 'video/mp4'
            elif 'image' in content_type: content_type = 'image/jpeg'
            else: content_type = 'video/mp4' # é»˜è®¤ä¿å‘½ç¬¦

        print(f"[Bundleä¸Šä¼ ] æ­¥éª¤1: åˆå§‹åŒ–ä¸Šä¼  - {filename} ({content_type})")
        
        # æ­¥éª¤1: åˆå§‹åŒ–ä¸Šä¼ 
        init_headers = {
            "x-api-key": API_KEY,
            "Content-Type": "application/json"
        }
        
        init_payload = {
            "fileName": filename,
            "mimeType": content_type,
            "teamId": get_current_team_id()
        }
        
        init_response = request_with_proxy_fallback(
            'post',
            f"{BASE_URL}/upload/init",
            headers=init_headers,
            json=init_payload
        )
        
        print(f"[Bundleä¸Šä¼ ] åˆå§‹åŒ–å“åº”: {init_response.status_code}")
        
        if init_response.status_code not in [200, 201]:
            error_text = init_response.text[:300]
            print(f"[Bundleä¸Šä¼ ] åˆå§‹åŒ–å¤±è´¥: {error_text}")
            return None, f"åˆå§‹åŒ–å¤±è´¥ ({init_response.status_code}): {error_text}"
        
        init_data = init_response.json()
        upload_url = init_data.get('url')
        upload_path = init_data.get('path')
        
        if not upload_url or not upload_path:
            print(f"[Bundleä¸Šä¼ ] åˆå§‹åŒ–å“åº”ç¼ºå°‘urlæˆ–path: {init_data}")
            return None, "åˆå§‹åŒ–å“åº”æ ¼å¼é”™è¯¯"
        
        print(f"[Bundleä¸Šä¼ ] âœ“ åˆå§‹åŒ–æˆåŠŸ")
        print(f"[Bundleä¸Šä¼ ] Upload URL: {upload_url[:50]}...")
        print(f"[Bundleä¸Šä¼ ] Path: {upload_path}")
        
        # æ­¥éª¤2: ä¸Šä¼ äºŒè¿›åˆ¶æ–‡ä»¶
        print(f"[Bundleä¸Šä¼ ] æ­¥éª¤2: ä¸Šä¼ äºŒè¿›åˆ¶æ–‡ä»¶...")
        
        # ğŸš¨ ä¼˜åŒ–ï¼šé¿å…å°†å¤§æ–‡ä»¶å…¨éƒ¨è¯»å…¥å†…å­˜
        file_data = file 
        file_size = "Unknown"
        
        if hasattr(file, 'read'):
            try:
                file.seek(0, 2)
                file_size = file.tell()
                file.seek(0)
            except:
                pass
        elif isinstance(file, bytes):
            file_size = len(file)
            
        print(f"[Bundleä¸Šä¼ ] æ–‡ä»¶å¤§å°: {file_size} bytes")

        
        # PUTä¸Šä¼ åˆ°S3 - 10sè¿æ¥ï¼Œ1800sè¯»å–/å†™å…¥ï¼ˆå¯¹äºè¶…å¤§è§†é¢‘æˆ–ææ…¢ç½‘ç»œï¼‰
        put_response = request_with_proxy_fallback(
            'put',
            upload_url,
            data=file_data,
            headers={"Content-Type": content_type},
            timeout=(30, 1800) 
        )

        
        print(f"[Bundleä¸Šä¼ ] äºŒè¿›åˆ¶ä¸Šä¼ å“åº”: {put_response.status_code}")
        
        if put_response.status_code not in [200, 201, 204]:
            error_text = put_response.text[:300] or f"HTTP {put_response.status_code}"
            print(f"[Bundleä¸Šä¼ ] äºŒè¿›åˆ¶ä¸Šä¼ å¤±è´¥: {error_text}")
            return None, f"äºŒè¿›åˆ¶ä¸Šä¼ é˜¶æ®µå¤±è´¥ ({put_response.status_code}): {error_text}"
        
        print(f"[Bundleä¸Šä¼ ] âœ“ äºŒè¿›åˆ¶ä¸Šä¼ æˆåŠŸ")
        
        # æ­¥éª¤3: å®Œæˆä¸Šä¼ 
        print(f"[Bundleä¸Šä¼ ] æ­¥éª¤3: å®Œæˆä¸Šä¼ ...")
        
        finalize_payload = {
            "path": upload_path,
            "teamId": get_current_team_id()
        }
        
        finalize_response = request_with_proxy_fallback(
            'post',
            f"{BASE_URL}/upload/finalize",
            headers=init_headers,
            json=finalize_payload
        )
        
        print(f"[Bundleä¸Šä¼ ] å®Œæˆå“åº”: {finalize_response.status_code}")
        
        if finalize_response.status_code not in [200, 201]:
            error_text = finalize_response.text[:300]
            print(f"[Bundleä¸Šä¼ ] å®Œæˆå¤±è´¥: {error_text}")
            return None, f"å®Œæˆå¤±è´¥ ({finalize_response.status_code}): {error_text}"
        
        finalize_data = finalize_response.json()
        
        # æ‰“å°å®Œæ•´å“åº”ä»¥ä¾›è°ƒè¯•
        print(f"[Bundleä¸Šä¼ ] å®Œæˆå“åº”å®Œæ•´å†…å®¹:")
        print(f"{json.dumps(finalize_data, indent=2, ensure_ascii=False)}")
        
        # å°è¯•å¤šç§å¯èƒ½çš„IDå­—æ®µ
        upload_id = (
            finalize_data.get('id') or 
            finalize_data.get('uploadId') or 
            finalize_data.get('fileId') or
            finalize_data.get('mediaId') or
            finalize_data.get('data', {}).get('id')
        )
        
        if not upload_id:
            print(f"[Bundleä¸Šä¼ ] âš ï¸ è­¦å‘Šï¼šå®Œæˆå“åº”ä¸­æœªæ‰¾åˆ°IDå­—æ®µ")
            print(f"[Bundleä¸Šä¼ ] å¯ç”¨çš„å­—æ®µ: {list(finalize_data.keys())}")
            return None, f"å®Œæˆå“åº”ç¼ºå°‘uploadIdã€‚å“åº”å†…å®¹: {json.dumps(finalize_data)[:200]}"
        
        print(f"[Bundleä¸Šä¼ ] âœ“âœ“âœ“ ä¸Šä¼ å®Œå…¨æˆåŠŸ! Upload ID: {upload_id}")
        return upload_id, None
        
    except Exception as e:
        print(f"[Bundleä¸Šä¼ ] å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None, f"ä¸Šä¼ å¼‚å¸¸: {str(e)}"

def download_resource(url, retries=5):
    """å¢å¼ºçš„èµ„æºä¸‹è½½åŠŸèƒ½ï¼Œæ”¯æŒåˆ†å—ä¸‹è½½å’Œå¤šé‡é‡è¯•ç­–ç•¥"""
    print(f"ğŸ¯ [ä¸‹è½½ä»»åŠ¡] å¼€å§‹ä¸‹è½½: {url[:100]}...")
    
    for attempt in range(retries):
        try:
            print(f"ğŸ“¥ [å°è¯• {attempt+1}/{retries}] æ­£åœ¨è¿æ¥æœåŠ¡å™¨...")
            
            # æ„å»ºæ›´å®Œæ•´çš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "*/*",
                "Accept-Encoding": "gzip, deflate, br",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Connection": "keep-alive",
                # å…³é”®ï¼šæ·»åŠ  Referer é˜²æ­¢æŸäº› CDN çš„é˜²ç›—é“¾
                "Referer": url.split('?')[0] if '?' in url else url,
            }
            
            # å¦‚æœæ˜¯é˜¿é‡Œäº‘ OSSï¼Œæ·»åŠ ç‰¹æ®Šå¤„ç†
            if 'aliyuncs.com' in url or 'oss-cn' in url:
                print(f"ğŸ”§ [OSSæ£€æµ‹] è¯†åˆ«ä¸ºé˜¿é‡Œäº‘OSSï¼Œä½¿ç”¨ä¸“ç”¨ä¸‹è½½ç­–ç•¥...")
                # ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„ç¼–ç å‚æ•°
                headers["Accept-Encoding"] = "identity"
            
            # ğŸš€ ä¼˜åŒ–ï¼šåˆç†çš„è¿æ¥å’Œä¸‹è½½è¶…æ—¶
            timeout = (15, 180) # 15s connect, 180s read
            
            # ä½¿ç”¨æµå¼ä¸‹è½½ï¼Œé¿å…å¤§æ–‡ä»¶ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
            print(f"â¬ [æµå¼ä¸‹è½½] å¼€å§‹æ¥æ”¶æ•°æ®æµ... (è¶…æ—¶: 180ç§’)")
            resp = request_with_proxy_fallback('get', url, headers=headers, timeout=timeout, stream=True)
            
            if resp.status_code == 200:
                # è·å–æ–‡ä»¶å¤§å°
                content_length = resp.headers.get('Content-Length')
                if content_length:
                    size_mb = int(content_length) / (1024 * 1024)
                    print(f"ğŸ“¦ [æ–‡ä»¶ä¿¡æ¯] å¤§å°: {size_mb:.2f} MB, ç±»å‹: {resp.headers.get('Content-Type', 'æœªçŸ¥')}")
                
                # åˆ†å—è¯»å–å†…å®¹
                chunks = []
                downloaded = 0
                chunk_size = 2 * 1024 * 1024  # 2MB per chunk (åŠ å¤§å—å¤§å°æå‡é€Ÿåº¦)
                
                print(f"â³ [ä¸‹è½½è¿›åº¦] å¼€å§‹æ¥æ”¶æ•°æ®...")
                for chunk in resp.iter_content(chunk_size=chunk_size):
                    if chunk:
                        chunks.append(chunk)
                        downloaded += len(chunk)
                        if content_length:
                            progress = (downloaded / int(content_length)) * 100
                            # æ¯10MBæ‰“å°ä¸€æ¬¡è¿›åº¦
                            if downloaded % (10 * 1024 * 1024) < chunk_size:
                                print(f"â³ [ä¸‹è½½è¿›åº¦] {progress:.1f}% ({downloaded/(1024*1024):.1f}MB/{size_mb:.1f}MB)")
                
                # åˆå¹¶æ‰€æœ‰å—
                full_content = b''.join(chunks)
                print(f"âœ… [ä¸‹è½½æˆåŠŸ] å…±æ¥æ”¶ {len(full_content)/(1024*1024):.2f} MB")
                
                # åˆ›å»ºä¸€ä¸ªç±»ä¼¼ requests.Response çš„å¯¹è±¡
                class MockResponse:
                    def __init__(self, content, headers, status_code=200):
                        self.content = content
                        self.headers = headers
                        self.status_code = status_code
                        self.ok = True
                
                return MockResponse(full_content, resp.headers, 200)
            
            elif resp.status_code == 403:
                print(f"ğŸš« [è®¿é—®æ‹’ç»] HTTP 403 - å¯èƒ½æ˜¯é˜²ç›—é“¾æˆ–æƒé™é—®é¢˜")
                if attempt < retries - 1:
                    import time
                    wait_time = (attempt + 1) * 2
                    print(f"â° [ç­‰å¾…é‡è¯•] {wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
            else:
                print(f"âš ï¸ [å“åº”å¼‚å¸¸] HTTP {resp.status_code}")
                
        except requests.exceptions.Timeout as e:
            print(f"â±ï¸ [è¶…æ—¶] ç¬¬ {attempt+1} æ¬¡å°è¯•è¶…æ—¶: {str(e)[:100]}")
            if attempt < retries - 1:
                print(f"ğŸ”„ [é‡è¯•] å°†åœ¨5ç§’åé‡è¯•...")
                import time
                time.sleep(5)
        except requests.exceptions.ConnectionError as e:
            print(f"ğŸ”Œ [è¿æ¥é”™è¯¯] ç¬¬ {attempt+1} æ¬¡è¿æ¥å¤±è´¥: {str(e)[:100]}")
            if attempt < retries - 1:
                import time
                time.sleep(3)
        except Exception as e:
            print(f"âŒ [æœªçŸ¥é”™è¯¯] ç¬¬ {attempt+1} æ¬¡å°è¯•å¼‚å¸¸: {type(e).__name__}: {str(e)[:200]}")
            import traceback
            traceback.print_exc()
    
    print(f"ğŸ’” [ä¸‹è½½å¤±è´¥] æ‰€æœ‰ {retries} æ¬¡å°è¯•å‡å¤±è´¥")
    return None

def download_and_proxy_upload(url):
    """ä» URL ä¸‹è½½å¹¶ä¸Šä¼ åˆ° Bundleï¼Œè¿”å› (upload_id, error_msg)"""
    print(f"ğŸŒ [æ•‘æ´ä¸‹è½½] æ­£åœ¨å°è¯•ä¸‹è½½èµ„æº: {url[:100]}...")
    resp = download_resource(url)
    if not resp:
        return None, "æ— æ³•ä¸‹è½½æºè§†é¢‘ï¼Œè¯·æ£€æŸ¥ç½‘ç»œé“¾æ¥æ˜¯å¦æœ‰æ•ˆ"
    
    # æ™ºèƒ½è¯†åˆ«æ–‡ä»¶åå’Œç±»å‹
    import mimetypes
    content_type = resp.headers.get('Content-Type', 'video/mp4')
    filename = url.split('/')[-1].split('?')[0] or "asset"
    
    # è‡ªåŠ¨è¯†åˆ«åç¼€
    if '.' not in filename:
        ext = mimetypes.guess_extension(content_type) or '.mp4'
        filename += ext
    elif not filename.lower().endswith(('.mp4', '.png', '.jpg', '.jpeg', '.gif')):
        # å³ä½¿æœ‰ç‚¹ï¼Œå¦‚æœæ˜¯å‚æ•°å¯¼è‡´çš„ï¼Œä¹ŸåŠ ä¸Šæ­£ç¡®åç¼€
        ext = mimetypes.guess_extension(content_type) or '.mp4'
        filename += ext

    print(f"ğŸš€ [æ•‘æ´ä¸Šä¼ ] ä¸‹è½½æˆåŠŸ ({len(resp.content)}å­—èŠ‚), å‡†å¤‡åŒæ­¥è‡³äº‘ç«¯... ç±»å‹: {content_type}, æ–‡ä»¶å: {filename}")
    upload_id, error = proxy_upload_to_bundle(resp.content, filename, content_type)
    if upload_id:
        print(f"âœ… [æ•‘æ´æˆåŠŸ] å·²è·å¾—ä¸Šä¼  ID: {upload_id}")
        return upload_id, None
    else:
        print(f"âŒ [æ•‘æ´å¤±è´¥] åŒæ­¥äº‘ç«¯å¤±è´¥: {error}")
        return None, f"æ–‡ä»¶åŒæ­¥äº‘ç«¯å¤±è´¥: {error}"

# --- é™æ€æ–‡ä»¶æœåŠ¡ ---
DB_PATH = "platform.db"

def get_db_connection():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def init_db():
    conn = get_db_connection()
    # åˆ›å»ºç”¨æˆ·è¡¨
    conn.execute('''
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        email TEXT UNIQUE NOT NULL,
        password TEXT NOT NULL,
        name TEXT
    )
    ''')
    # åˆ›å»ºç¤¾äº¤è´¦å·æœ¬åœ°åŒæ­¥è¡¨
    conn.execute('''
    CREATE TABLE IF NOT EXISTS social_accounts (
        id TEXT PRIMARY KEY,
        user_id INTEGER,
        team_id TEXT,
        platform TEXT,
        handle TEXT,
        name TEXT,
        avatar TEXT,
        status TEXT,
        last_sync TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (user_id) REFERENCES users (id)
    )
    ''')

    # åˆ›å»ºè¯„è®º/å›å¤è¡¨
    conn.execute('''
    CREATE TABLE IF NOT EXISTS comments (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        post_id TEXT,
        account_id TEXT,
        platform TEXT,
        author_name TEXT,
        author_avatar TEXT,
        content TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        is_reply INTEGER DEFAULT 0,
        parent_id INTEGER
    )
    ''')

    # åˆ›å»ºå¸–å­è®°å½•è¡¨ (ç”¨äºæœ¬åœ°ç¼“å­˜å’ŒåŒæ­¥æ•°æ®)
    conn.execute('''
    CREATE TABLE IF NOT EXISTS posts (
        id TEXT PRIMARY KEY,
        team_id TEXT,
        content TEXT,
        status TEXT,
        post_date TEXT,
        accounts_json TEXT,
        media_json TEXT,
        views INTEGER DEFAULT 0,
        likes INTEGER DEFAULT 0,
        comments_count INTEGER DEFAULT 0,
        shares INTEGER DEFAULT 0,
        gmv FLOAT DEFAULT 0.0,
        last_sync TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    
    # åˆ›å»ºæ™ºèƒ½ä½“å¹¿åœºè¡¨
    conn.execute('''
    CREATE TABLE IF NOT EXISTS ai_agents (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER,
        name TEXT NOT NULL,
        tags TEXT,
        description TEXT,
        logic TEXT,
        icon TEXT,
        author TEXT,
        usage INTEGER DEFAULT 0,
        rating FLOAT DEFAULT 5.0,
        price TEXT DEFAULT 'å…è´¹è®¢é˜…',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    
    # æ’å…¥æ¼”ç¤ºè´¦å·å’Œåˆå§‹èƒ½åŠ›
    try:
        hashed_pw = generate_password_hash("123456")
        conn.execute("INSERT OR IGNORE INTO users (email, password, name) VALUES (?, ?, ?)", 
                     ("demo@example.com", hashed_pw, "Creative User"))
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–å®˜æ–¹èƒ½åŠ› (ç¤ºä¾‹)
        count = conn.execute("SELECT COUNT(*) FROM ai_agents").fetchone()[0]
        if count == 0:
            official_ones = [
                ("AIå°è¯´åŠ©æ‰‹", "å°è¯´,åˆ›ä½œ", "ä¸“ä¸šçš„ç½‘æ–‡åŠ©æ‰‹ï¼Œç†Ÿæ‚‰å„ç§æµæ´¾å¥—è·¯ã€‚", "ä½ æ˜¯ä¸€ä¸ªé‡‘ç‰Œå°è¯´ç¼–è¾‘...", "book", "å®˜æ–¹å›¢é˜Ÿ", 15200, 4.9, "å®˜æ–¹èƒ½åŠ›"),
                ("å‰ªè¾‘å¤§å¸ˆ", "è§†é¢‘,å·¥ä½œæµ", "ä¸€é”®ç”Ÿæˆè§†é¢‘è„šæœ¬å’Œå‰ªè¾‘å»ºè®®ã€‚", "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±åˆ†é•œå¸ˆ...", "scissors", "å®˜æ–¹å›¢é˜Ÿ", 8400, 4.8, "å®˜æ–¹èƒ½åŠ›"),
                ("çŸ­å‰§å»é‡ä¸“å®¶", "çŸ­å‰§,TikTok", "é’ˆå¯¹æµ·å¤–ç®—æ³•ä¼˜åŒ–çš„è§†é¢‘é‡æ„æµã€‚", "#è§’è‰²è§„èŒƒ\nä½ æ˜¯ä¸€ä¸ªå»é‡ä¸“å®¶...", "zap", "çŸ­å‰§è€å…µ", 5400, 4.9, "Â¥99/æœˆ")
            ]
            conn.executemany('''
                INSERT INTO ai_agents (name, tags, description, logic, icon, author, usage, rating, price)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', official_ones)
    except Exception as e:
        print(f"Init DB Error: {e}")
        
    conn.commit()
    conn.close()

# åˆå§‹åŒ–æ•°æ®åº“
init_db()

def get_headers():
    return {
        "x-api-key": API_KEY,
        "Content-Type": "application/json"
    }

def get_current_team_id():
    """åŠ¨æ€è·å–å½“å‰ API Key å¯¹åº”çš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆå›¢é˜Ÿ ID"""
    if hasattr(get_current_team_id, '_cache') and get_current_team_id._cache:
        return get_current_team_id._cache
    
    try:
        # 1. å°è¯•ä»å…¬å¼€ API è·å–åˆ—è¡¨
        res = request_with_proxy_fallback('get', f"{BASE_URL}/team", headers=get_headers(), timeout=10)
        if res.ok:
            data = res.json()
            teams = data if isinstance(data, list) else data.get('teams', [])
            if teams and len(teams) > 0:
                get_current_team_id._cache = str(teams[0].get('id'))
                print(f"ğŸ” [Team] å‘ç°ä¸»å›¢é˜Ÿ: {get_current_team_id._cache}")
                return get_current_team_id._cache
    except Exception as e:
        print(f"âš ï¸ [Team] APIè·å–å¤±è´¥: {e}")
    
    # 2. å°è¯•ä»æ•°æ®åº“åæ¨
    try:
        conn = get_db_connection()
        row = conn.execute("SELECT team_id FROM social_accounts WHERE team_id IS NOT NULL LIMIT 1").fetchone()
        conn.close()
        if row and row['team_id']:
            get_current_team_id._cache = str(row['team_id'])
            return get_current_team_id._cache
    except:
        pass

    # 3. æœ€åå›é€€
    print(f"âš ï¸ [Team] æ¢æµ‹å¤±è´¥ï¼Œå›é€€è‡³: {TEAM_ID}")
    return TEAM_ID

def _fetch_all_accounts_minimal():
    """åŠ©æ‰‹å‡½æ•°ï¼šè·å–æ‰€æœ‰å·²è¿æ¥è´¦å·çš„ç²¾ç®€ä¿¡æ¯ï¼ˆID, Name, Handle, Avatar, Typeï¼‰"""
    accounts_map = {}
    try:
        headers = get_headers()
        team_id = get_current_team_id()
        if not team_id: return {}
        
        # æ¢æµ‹ Team è¯¦æƒ…
        url = f"{BASE_URL}/team/{team_id}"
        res = request_with_proxy_fallback('get', url, headers=headers, timeout=5)
        if res.status_code == 200:
            data = res.json()
            for key in ['socialAccounts', 'socialConnections', 'accounts', 'socialSets']:
                if key in data and isinstance(data[key], list) and len(data[key]) > 0:
                    for item in data[key]:
                        acc = item.get('socialAccount', item)
                        acc_id = str(acc.get('id'))
                        accounts_map[acc_id] = {
                            "id": acc_id,
                            "type": (acc.get('type') or 'SOCIAL').upper(),
                            "name": acc.get('displayName') or acc.get('username') or 'Account',
                            "handle": acc.get('username') or acc.get('handle') or 'user',
                            "avatar": acc.get('avatarUrl') or f"https://api.dicebear.com/7.x/initials/svg?seed={acc_id}"
                        }
                    break
    except Exception as e:
        print(f"Error in _fetch_all_accounts_minimal: {e}")
    return accounts_map

# --- ç”¨æˆ·è®¤è¯è·¯ç”± ---

@app.route('/api/login', methods=['POST'])
def login():
    data = request.json
    email = data.get('email')
    password = data.get('password')
    
    conn = get_db_connection()
    user = conn.execute("SELECT * FROM users WHERE email = ?", (email,)).fetchone()
    conn.close()
    
    if user and check_password_hash(user['password'], password):
        # ç®€å•æ¨¡æ‹Ÿï¼šè¿”å›ç”¨æˆ·ä¿¡æ¯
        return jsonify({
            "success": True, 
            "user": {"id": user['id'], "email": user['email'], "name": user['name']}
        })
    return jsonify({"success": False, "message": "Invalid email or password"}), 401

@app.route('/api/integrations', methods=['GET'])
def get_integrations():
    # è¿”å›æ”¯æŒçš„å¹³å°åˆ—è¡¨ï¼ˆé€‚é…å›¾2çš„ä¸­æ–‡å’Œé¢œè‰²ï¼‰
    platforms = [
        {"id": "facebook", "name": "Facebook", "color": "bg-blue-600", "desc": "å‘å¸ƒåˆ°å…¬å…±ä¸»é¡µå’Œç¾¤ç»„ã€‚"},
        {"id": "twitter", "name": "X (Twitter)", "color": "bg-slate-900", "desc": "å³æ—¶å‘å¸ƒæ¨æ–‡å’Œä¸»é¢˜å¸–ã€‚"},
        {"id": "instagram", "name": "Instagram", "color": "bg-pink-600", "desc": "åˆ†äº«ç…§ç‰‡ã€Reels å’Œå¿«æ‹ã€‚"},
        {"id": "linkedin", "name": "LinkedIn", "color": "bg-blue-700", "desc": "å‘å¸ƒä¸ªäººå’Œå…¬å¸ä¸»é¡µçš„ä¸“ä¸šåŠ¨æ€ã€‚"},
        {"id": "youtube", "name": "YouTube", "color": "bg-red-600", "desc": "ä¸Šä¼ çŸ­è§†é¢‘å’Œé•¿è§†é¢‘ã€‚"},
        {"id": "tiktok", "name": "TikTok", "color": "bg-black", "desc": "åˆ†äº«çƒ­é—¨çŸ­è§†é¢‘ã€‚"}
    ]
    return jsonify(platforms)

# --- ç¤¾äº¤è´¦å·åŒæ­¥è·¯ç”± ---

@app.route('/api/accounts', methods=['GET'])
def get_connected_accounts():
    """å…¨èƒ½æ¢é’ˆç‰ˆ V3ï¼šä¿®å¤è´¦æˆ·è·å–é€»è¾‘"""
    try:
        print(f"\nğŸ” --- å¼€å§‹å…¨èƒ½æ¢é’ˆ V3 (é’ˆå¯¹ Team: {TEAM_ID}) ---")
        headers = get_headers()
        bundle_accounts = []
        
        # æ¢æµ‹ç‚¹ 1: Team è¯¦æƒ…é¡µ
        team_detail_url = f"{BASE_URL}/team/{TEAM_ID}"
        print(f"ğŸ‘‰ æ¢æµ‹ç‚¹ 1 (Team è¯¦æƒ…): {team_detail_url}")
        try:
            res = request_with_proxy_fallback('get', team_detail_url, headers=headers, timeout=10)
            if res.status_code == 200:
                team_data = res.json()
                print(f"   âœ… [Team è¯¦æƒ…] æˆåŠŸæŠ“å–æ•°æ®ï¼Keys: {list(team_data.keys())}")
                
                # ä¼˜å…ˆçº§å­—æ®µæ£€æŸ¥ - åªå¤„ç†éç©ºåˆ—è¡¨
                found_key = None
                for key in ['socialAccounts', 'socialConnections', 'accounts', 'socialSets', 'channels', 'integrations']:
                    if key in team_data and isinstance(team_data[key], list) and len(team_data[key]) > 0:
                        found_key = key
                        print(f"   ğŸ¯ åœ¨ '{found_key}' å­—æ®µå‘ç°äº† {len(team_data[found_key])} ä¸ªè´¦å·ï¼")
                        break
                
                if found_key:
                    for idx, item in enumerate(team_data[found_key]):
                        try:
                            # æå–è´¦å·ä¿¡æ¯ (æœ‰çš„ API è¿”å›çš„æ˜¯åŒ…è£…å¯¹è±¡ï¼Œæœ‰çš„æ˜¯ç›´æ¥å¯¹è±¡)
                            acc_obj = item
                            if 'socialAccount' in item: # åŒ…è£…æƒ…å†µ
                                acc_obj = item['socialAccount']
                            
                            print(f"   å¤„ç†è´¦å· {idx + 1}: type={acc_obj.get('type')}, username={acc_obj.get('username')}")
                            
                            acc_data = {
                                "id": str(acc_obj.get('id')),
                                "platform": (acc_obj.get('type') or acc_obj.get('platform') or 'Social').capitalize(),
                                "handle": acc_obj.get('username') or acc_obj.get('handle') or acc_obj.get('name') or 'Connected Account',
                                "name": acc_obj.get('displayName') or acc_obj.get('name') or 'Account',
                                "avatar": acc_obj.get('avatarUrl') or acc_obj.get('image') or acc_obj.get('avatar') or f"https://api.dicebear.com/7.x/initials/svg?seed={acc_obj.get('displayName', 'Account')}",
                                "status": "active"
                            }
                            bundle_accounts.append(acc_data)
                            print(f"      âœ… æˆåŠŸæå–: {acc_data['platform']} - {acc_data['handle']}")
                        except Exception as parse_error:
                            print(f"      âŒ è§£æè´¦å· {idx + 1} å¤±è´¥: {parse_error}")
                else:
                    print(f"   âš ï¸ åœ¨ Team è¯¦æƒ…ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•°æ®çš„è´¦å·å­—æ®µã€‚")
        except Exception as e:
            print(f"   âŒ Team è¯¦æƒ…æ¢æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

        # å¦‚æœæ¢æµ‹ç‚¹1æ²¡æŠ“åˆ°ï¼Œå°è¯•æ¢æµ‹ç‚¹ 2: å›¢é˜Ÿåˆ—è¡¨ (List View)
        if not bundle_accounts:
            all_teams_url = f"{BASE_URL}/team"
            print(f"ğŸ‘‰ æ¢æµ‹ç‚¹ 2 (å°è¯•å›¢é˜Ÿåˆ—è¡¨): {all_teams_url}")
            try:
                res = request_with_proxy_fallback('get', all_teams_url, headers=headers, timeout=10)
                if res.status_code == 200:
                    data = res.json()
                    # å…¼å®¹åˆ†é¡µç»“æ„ { data: [...], total: N }
                    teams_list = data.get('data', []) if isinstance(data, dict) else data
                    
                    target_team = next((t for t in teams_list if t.get('id') == TEAM_ID), None)
                    if target_team:
                        print(f"   âœ… åœ¨åˆ—è¡¨ä¸­æ‰¾åˆ°äº†ç›®æ ‡ Teamã€‚Keys: {list(target_team.keys())}")
                        # åŒæ ·æ£€æŸ¥å­—æ®µï¼Œè¿™æ¬¡é‡ç‚¹æ‰¾ socialConnections
                        for key in ['socialConnections', 'socialAccounts', 'accounts']:
                            if key in target_team and isinstance(target_team[key], list) and len(target_team[key]) > 0:
                                print(f"   ğŸ¯ åœ¨åˆ—è¡¨è§†å›¾ '{key}' ä¸­å‘ç°äº† {len(target_team[key])} ä¸ªè´¦å·ï¼")
                                for item in target_team[key]:
                                    acc_data = {
                                        "id": str(item.get('id')),
                                        "platform": (item.get('type') or item.get('platform') or 'Social').capitalize(),
                                        "handle": item.get('username') or item.get('handle') or item.get('name'),
                                        "name": item.get('displayName') or item.get('name'),
                                        "avatar": item.get('avatarUrl') or item.get('image') or item.get('avatar'),
                                        "status": "active"
                                    }
                                    bundle_accounts.append(acc_data)
                                break
            except Exception as e:
                print(f"   âŒ å›¢é˜Ÿåˆ—è¡¨æ¢æµ‹å¤±è´¥: {e}")

        # è·å–å½“å‰æœ¬åœ°ç¼“å­˜
        conn = get_db_connection()
        cached_rows = conn.execute("SELECT COUNT(*) FROM social_accounts").fetchone()[0]
        conn.close()

        # å¦‚æœæœ¬åœ°æ²¡æœ‰æ•°æ®ï¼Œæˆ–è€…æ¢æµ‹åˆ°æ–°æ•°æ®ï¼Œæ‰è¿›è¡Œæ›´æ–°
        if bundle_accounts:
            # ğŸ”§ ä¿®å¤é‡å¤é—®é¢˜:å…ˆå»é‡bundle_accountsåˆ—è¡¨
            seen_ids = set()
            unique_accounts = []
            for acc in bundle_accounts:
                if acc['id'] not in seen_ids:
                    seen_ids.add(acc['id'])
                    unique_accounts.append(acc)
            
            bundle_accounts = unique_accounts
            print(f"âœ¨ åŒæ­¥æ¢æµ‹å‘ç° {len(bundle_accounts)} ä¸ªæœ‰æ•ˆè´¦å·")
            
            conn = get_db_connection()
            # åªæœ‰åœ¨ç¡®å®æŠ“å–åˆ°æ•°æ®æ—¶æ‰è¦†ç›–æœ¬åœ°ï¼Œé¿å…å› ä¸ºç½‘ç»œå¼‚å¸¸å¯¼è‡´æœ¬åœ°æ¸…ç©º
            conn.execute('DELETE FROM social_accounts')
            for acc in bundle_accounts:
                conn.execute('''
                    INSERT INTO social_accounts (id, platform, handle, name, avatar, status, last_sync, team_id)
                    VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, ?)
                ''', (acc['id'], acc['platform'], acc['handle'], acc['name'], acc['avatar'], acc['status'], TEAM_ID))
            conn.commit()
            conn.close()
            print(f"ğŸ‰ æˆåŠŸåŒæ­¥æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“")
        elif cached_rows == 0:
            print("âš ï¸ æ¢é’ˆæœªå‘ç°æ•°æ®ä¸”æœ¬åœ°ä¸ºç©º")
        else:
            print("â„¹ï¸ æ¢é’ˆæœªå‘ç°æ–°æ•°æ®ï¼Œä¿ç•™æœ¬åœ°ç¼“å­˜")

        # è¿”å›æ•°æ®åº“é‡Œçš„æ‰€æœ‰è´¦å·
        conn = get_db_connection()
        rows = conn.execute("SELECT * FROM social_accounts WHERE status = 'active'").fetchall()
        conn.close()
        
        result = [dict(row) for row in rows]
        print(f"ğŸ“¤ [Accounts] è¿”å› {len(result)} ä¸ªè´¦å·åˆ°å‰ç«¯")
        return jsonify(result)
        
    except Exception as e:
        print(f"âŒ æ¢é’ˆ V3 å´©æºƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify([])

@app.route('/api/connect-url', methods=['POST'])
def create_portal_link():
    data = request.json
    platform_id = data.get('platformId') # å‰ç«¯ä¼ æ¥çš„ idï¼Œå¦‚ 'youtube'
    
    # --- å…³é”®ä¿®æ­£ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå¹³å° ID é€šå¸¸éœ€è¦å¤§å†™ ---
    type_map = {
        "twitter": "TWITTER",
        "facebook": "FACEBOOK",
        "instagram": "INSTAGRAM",
        "linkedin": "LINKEDIN",
        "youtube": "YOUTUBE",
        "tiktok": "TIKTOK"
    }
    target_type = type_map.get(platform_id)
    
    team_id = get_current_team_id()
    if not team_id:
        return jsonify({"error": "æœªæ‰¾åˆ°å›¢é˜Ÿ IDï¼Œè¯·ç¡®ä¿ TEAM_ID å·²æ­£ç¡®è®¾ç½®ã€‚"}), 400
        
    # --- å…³é”®ä¿®æ­£ï¼šæ­£ç¡®çš„ API è·¯å¾„æ˜¯ /create-portal-link ---
    url = f"{BASE_URL}/social-account/create-portal-link"
    
    payload = {
        "teamId": team_id,
        "socialAccountTypes": [target_type] if target_type else [],
        "redirectUrl": "http://localhost:5000/api/callback",
    }
    
    try:
        print(f"--- å‘é€è¯·æ±‚åˆ° Bundle API: {url} ---")
        response = request_with_proxy_fallback('post', url, headers=get_headers(), json=payload)
        return jsonify(response.json())
    except Exception as e:
        print(f"Error creating portal link: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/publish', methods=['POST'])
def publish_post():
    """å‘å¸ƒå¸–å­åˆ°é€‰ä¸­å¹³å°"""
    try:
        content = None
        account_ids = []
        media_files = []
        media_urls = []
        use_bundle_upload = True
        file_logs = []

        # æ”¯æŒ JSON æˆ– FormData (ç”¨äºæ–‡ä»¶ä¸Šä¼ )
        if request.is_json:
            data = request.json
            content = data.get('content')
            account_ids = data.get('accountIds', [])
            media_files = data.get('media', []) or data.get('mediaUrls', [])
        else:
            # FormData æƒ…å†µ
            content = request.form.get('content')
            account_ids = json.loads(request.form.get('accountIds', '[]'))
            
            # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ - æ™ºèƒ½åŒæ¨¡å¼
            uploaded_files = request.files.getlist('media')
            
            print(f"[å‘å¸ƒ] æ”¶åˆ° {len(uploaded_files)} ä¸ªæ–‡ä»¶ä¸Šä¼ è¯·æ±‚")
            
            for idx, file in enumerate(uploaded_files):
                if file and file.filename:
                    print(f"[å‘å¸ƒ] å¤„ç†æ–‡ä»¶ {idx + 1}: {file.filename}")
                    
                    filename = file.filename
                    content_type = file.content_type or mimetypes.guess_type(filename)[0] or 'application/octet-stream'
                    
                    # 1. ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨ (æ¨¡æ‹Ÿ "æ•°æ®åº“" æŒä¹…åŒ–)
                    upload_dir = os.path.join(os.getcwd(), 'uploads')
                    if not os.path.exists(upload_dir):
                        os.makedirs(upload_dir)
                    
                    save_path = os.path.join(upload_dir, filename)
                    file.save(save_path)
                    print(f"[å‘å¸ƒ] âœ… æ–‡ä»¶å·²å®Œæ•´ä¿å­˜åˆ°æœ¬åœ°: {save_path}")

                    # 2. è°ƒç”¨ä¸Šä¼ é€»è¾‘ (ç°åœ¨æ”¯æŒæµå¼ä¸Šä¼ )
                    with open(save_path, 'rb') as f_local:
                        # âš ï¸ å°è¯• Bundle ä¸Šä¼ 
                        upload_id, bundle_error = proxy_upload_to_bundle(f_local, filename, content_type)

                    
                    if upload_id:
                        try:
                            # ç¡®å®š MIME ç±»å‹
                            file_mime = content_type
                            
                            # è™½ç„¶æœ¬åœ°æœ‰æ–‡ä»¶ï¼Œä½†ä¸ºäº†é¢„è§ˆï¼Œæˆ‘ä»¬è¿˜æ˜¯å°è¯•è·å–ä¸€ä¸ªé¢„è§ˆURL
                            # (æ³¨æ„: localhost URL å¤–éƒ¨æ— æ³•è®¿é—®ï¼Œè¿™é‡Œä»…ä¾›å†…éƒ¨è®°å½•)
                            local_url = f"{API_BASE}/uploads/{filename}"
                            
                            media_files.append({
                                "id": upload_id,
                                "url": local_url, 
                                "local_path": save_path,
                                "type": file_mime
                            })
                            print(f"[å‘å¸ƒ] âœ“ BundleåŸç”Ÿä¸Šä¼ æˆåŠŸï¼ŒID: {upload_id}")
                        except Exception as e:
                            print(f"[å‘å¸ƒ] ç”Ÿæˆé¢„è§ˆå¤±è´¥ï¼Œä»…ä½¿ç”¨ID: {e}")
                            media_files.append(upload_id)
                    else:
                        # Bundle ä¸Šä¼ å¤±è´¥ï¼Œé™çº§åˆ°å…è´¹å›¾åºŠ (åŸé€»è¾‘ä¿æŒä¸å˜)
                        print(f"[å‘å¸ƒ] Bundleä¸Šä¼ å¤±è´¥: {bundle_error}")
                        print(f"[å‘å¸ƒ] é™çº§åˆ°å…è´¹å›¾åºŠ...")
                        
                        # é‡æ–°è¯»å–æ–‡ä»¶ (å› ä¸ºæ˜¯è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œä¸å­˜åœ¨æŒ‡é’ˆé—®é¢˜ï¼Œä½†imgbbå‡½æ•°å¯èƒ½éœ€è¦bytesæˆ–file-like)
                        with open(save_path, 'rb') as f_reopen:
                            media_url, imgbb_error = upload_to_imgbb(f_reopen, filename=filename)
                        
                        if media_url:
                            media_urls.append(media_url)
                            use_bundle_upload = False
                            print(f"[å‘å¸ƒ] âœ“ å›¾åºŠä¸Šä¼ æˆåŠŸï¼ŒURL: {media_url[:50]}...")
                        else:
                            file_logs.append(f"æ–‡ä»¶ {file.filename}: Bundleå¤±è´¥({bundle_error}), å›¾åºŠå¤±è´¥({imgbb_error})")
                            print(f"[å‘å¸ƒ] âœ— æ‰€æœ‰ä¸Šä¼ æ–¹å¼å‡å¤±è´¥")
            
            # å¦‚æœä½¿ç”¨äº†å›¾åºŠï¼Œmedia_filesä½¿ç”¨URLs
            if not use_bundle_upload and media_urls:
                media_files = media_urls
            
            # å¤„ç†è¿œç¨‹ URL - å…³é”®ä¿®å¤ï¼
            # æ”¯æŒä¸¤ç§å½¢å¼ï¼šå•ä¸ªURL (mediaUrlså­—æ®µ) æˆ–å¤šä¸ªURL (mediaUrls[]æ•°ç»„)
            remote_urls = request.form.getlist('mediaUrls')
            if not remote_urls:
                # å¦‚æœ getlist æ²¡æœ‰è·å–åˆ°ï¼Œå°è¯•å•ä¸ªå€¼
                single_url = request.form.get('mediaUrls')
                if single_url:
                    remote_urls = [single_url]
            
            if remote_urls:
                print(f"[å‘å¸ƒ] æ”¶åˆ° {len(remote_urls)} ä¸ªè¿œç¨‹ URL")
                print(f"[å‘å¸ƒ] âš¡ ç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨ mediaUrlsï¼Œè®© Bundle API æœåŠ¡å™¨è‡ªå·±ä¸‹è½½")
                
                for idx, url in enumerate(remote_urls):
                    if url and url.strip():
                        print(f"[å‘å¸ƒ] ğŸ“ æ·»åŠ è¿œç¨‹URL {idx + 1}: {url[:70]}...")
                        # ç›´æ¥æ·»åŠ URLï¼Œä¸ä¸‹è½½
                        media_files.append(url)
                        use_bundle_upload = False  # æ ‡è®°ä½¿ç”¨URLæ¨¡å¼
            
            
            
            
            # æ¸…ç†
            remote_media_urls = [] 

        print(f"ğŸ“Š [å‘å¸ƒ] æœ€ç»ˆåª’ä½“åˆ—è¡¨:")
        print(f"  - åª’ä½“é¡¹æ•°é‡: {len(media_files)}")
        print(f"  - ä½¿ç”¨Bundleä¸Šä¼ : {use_bundle_upload}")
        if media_files:
            for idx, item in enumerate(media_files):
                item_str = str(item)[:80] if isinstance(item, str) else str(item)
                print(f"  - åª’ä½“ {idx + 1}: {item_str}")
        
        if not (content and content.strip()) and not media_files:
            error_msg = "å‘å¸ƒå¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸè¯†åˆ«åˆ°ä»»ä½•åª’ä½“å†…å®¹ã€‚"
            if file_logs:
                error_msg += "\nè¯Šæ–­è¯¦æƒ…:\n" + "\n".join([f"- {log}" for log in file_logs])
            print(f"âŒ [å‘å¸ƒ] {error_msg}")
            return jsonify({"error": error_msg}), 400
        
        if not account_ids:
            return jsonify({"error": "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå‘å¸ƒè´¦æˆ·"}), 400
            
        # 1. ä»æœ¬åœ°æ•°æ®åº“è·å–è¿™äº›è´¦æˆ·çš„å¹³å°ç±»å‹
        conn = get_db_connection()
        placeholders = ','.join(['?'] * len(account_ids))
        rows = conn.execute(f"SELECT id, platform FROM social_accounts WHERE id IN ({placeholders})", account_ids).fetchall()
        conn.close()
        
        if not rows:
            return jsonify({"error": "æœªæ‰¾åˆ°é€‰ä¸­çš„è´¦æˆ·ä¿¡æ¯ï¼Œè¯·å°è¯•åˆ·æ–°é¡µé¢"}), 404

        account_map = {row['id']: row['platform'].upper() for row in rows}
        target_platforms = list(set(account_map.values()))
        
        # 2. åª’ä½“æ ¡éªŒé€»è¾‘
        # æŸäº›å¹³å°å¿…é¡»ä¸Šä¼ åª’ä½“æ–‡ä»¶
        media_required_platforms = ['YOUTUBE', 'TIKTOK', 'INSTAGRAM']
        for platform in target_platforms:
            if platform in media_required_platforms and not media_files:
                return jsonify({
                    "error": f"å‘å¸ƒå¤±è´¥:{platform} å¹³å°å¿…é¡»ä¸Šä¼ åª’ä½“æ–‡ä»¶(è§†é¢‘æˆ–å›¾ç‰‡),ä¸èƒ½åªå‘å¸ƒçº¯æ–‡æœ¬ã€‚"
                }), 400

        # ğŸ”§ å¢å¼º: è§†é¢‘å®½é«˜æ¯”éªŒè¯ (é’ˆå¯¹ TikTok, YouTube, Instagram - X å¹³å°ä¸ºäº†é€Ÿåº¦è·³è¿‡)
        video_platforms = ['TIKTOK', 'YOUTUBE', 'INSTAGRAM']
        needs_strict_check = any(p in video_platforms for p in target_platforms)
        
        if needs_strict_check and media_files:
            print(f"[å‘å¸ƒ] ğŸ›¡ï¸ æ­£åœ¨è¿›è¡Œå¹³å°åˆè§„æ€§æ£€æŸ¥ (TikTok/YouTube/Instagram)...")
            
            for idx, m in enumerate(media_files):
                uploadId = None
                if isinstance(m, dict):
                    uploadId = m.get('id')
                elif isinstance(m, str) and not (m.startswith('http') or m.startswith('blob')):
                    uploadId = m
                
                if uploadId:
                    try:
                        check_url = f"{BASE_URL}/upload/{uploadId}"
                        check_res = request_with_proxy_fallback('get', check_url, headers=get_headers(), timeout=5)
                        
                        if check_res.status_code == 200:
                            video_info = check_res.json()
                            print(f"[å‘å¸ƒ] ğŸ” è§†é¢‘ {idx+1} å…ƒæ•°æ®: {json.dumps(video_info, ensure_ascii=False)}")
                            
                            width = video_info.get('width', 0)
                            height = video_info.get('height', 0)
                            mime_type = video_info.get('mimeType', '')
                            
                            if width > 0 and height > 0 and 'video' in mime_type.lower():
                                aspect_ratio = width / height
                                print(f"[å‘å¸ƒ] ğŸ“ˆ è§†é¢‘ {idx+1} åˆ†è¾¨ç‡: {width}x{height}, å®½é«˜æ¯”: {aspect_ratio:.3f}")
                                
                                # TikTok è¦æ±‚ç«–å± (9:16) æˆ–æ­£æ–¹å½¢ (1:1)
                                # æ¯”ä¾‹ > 1.1 çš„é€šå¸¸æ˜¯æ¨ªå± (16:9 çº¦ä¸º 1.77)
                                if aspect_ratio > 1.1:
                                    platform_names = [p for p in target_platforms if p in video_platforms]
                                    error_msg = (
                                        f"âŒ {'/'.join(platform_names)} å‘å¸ƒæ‹¦æˆªï¼šä¸æ”¯æŒæ¨ªå±è§†é¢‘\n\n"
                                        f"å½“å‰è§„æ ¼: {width}x{height} (å®½é«˜æ¯” {aspect_ratio:.2f}:1)\n"
                                        f"æ£€æµ‹åˆ°è§†é¢‘ä¸ºæ¨ªå±ï¼Œè€Œç›®æ ‡å¹³å°å¼ºåˆ¶è¦æ±‚ç«–å±æˆ–æ­£æ–¹å½¢æ ¼å¼ã€‚\n\n"
                                        f"âœ… å»ºè®®æ ¼å¼ï¼š\n"
                                        f"  â€¢ ç«–å±è§†é¢‘ (9:16) - 1080x1920\n"
                                        f"  â€¢ æ­£æ–¹å½¢ (1:1) - 1080x1080\n"
                                        f"  â€¢ å®½é«˜æ¯”åº” â‰¤ 1.0\n\n"
                                        f"ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥ä» AI æ™ºèƒ½ä½“è®¾ç½®ä¸­è°ƒæ•´è¾“å‡ºæ¯”ä¾‹ï¼Œæˆ–è€…ä½¿ç”¨å‰ªè¾‘å·¥å…·è£å‰ªåæ‰‹åŠ¨ä¸Šä¼ ã€‚"
                                    )
                                    print(f"[å‘å¸ƒ] ğŸš« å®½é«˜æ¯”æ‹¦æˆª: {width}x{height}")
                                    return jsonify({"error": error_msg}), 400
                                else:
                                    print(f"[å‘å¸ƒ] âœ… è§†é¢‘ {idx+1} å®½é«˜æ¯”æ£€æµ‹é€šè¿‡")
                        else:
                            print(f"[å‘å¸ƒ] âš ï¸ æ— æ³•è·å–èµ„æº {uploadId} çš„å…ƒæ•°æ® (HTTP {check_res.status_code})")
                    except Exception as check_error:
                        print(f"[å‘å¸ƒ] âš ï¸ å…ƒæ•°æ®æ ¡éªŒå¼‚å¸¸: {check_error}")
                else:
                    print(f"[å‘å¸ƒ] â„¹ï¸ èµ„æº {idx+1} è·³è¿‡æœ¬åœ°å®½é«˜æ¯”æ ¡éªŒ (æ—  uploadId)")

        # å‡†å¤‡ API éœ€è¦çš„åª’ä½“åˆ—è¡¨ (ä»… ID æˆ– URL å­—ç¬¦ä¸²)
        api_media_payload = []
        for m in media_files:
            if isinstance(m, dict):
                # å¦‚æœæ˜¯å­—å…¸ç»“æ„ (ä¸ºäº†åŒ…å«é¢„è§ˆURL),æå– ID
                api_media_payload.append(m.get('id') or m.get('url'))
            else:
                api_media_payload.append(m)
        
        # 3. æ„å»ºå‘å¸ƒ Payload
        import datetime
        future_now = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(seconds=10)
        now_iso = future_now.isoformat().replace('+00:00', 'Z')
        
        # ğŸ§ª åª’ä½“è´Ÿè½½ç²¾ç»†åŒ–å¤„ç†ï¼šåˆ†ç¦» ID (uploadIds) å’Œ URL (mediaUrls)
        all_upload_ids = [m for m in api_media_payload if isinstance(m, str) and not m.startswith('http')]
        all_media_urls = [m for m in api_media_payload if isinstance(m, str) and m.startswith('http')]
        
        print(f"[å‘å¸ƒ] åˆå§‹åª’ä½“åˆ†æµ: uploadIds={len(all_upload_ids)}, mediaUrls={len(all_media_urls)}")
        
        # ğŸš¨ æ•‘æ´é€»è¾‘ï¼šç¡®ä¿çŸ­è§†é¢‘å¹³å° (TikTok/YouTube/Instagram) å·²ç»æ‹¥æœ‰æœ‰æ•ˆçš„ uploadId
        # å¦‚æœå‰é¢æ­¥éª¤å·²æœ‰ uploadIdï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™å¯¹é—ç•™çš„ URL è¿›è¡Œæœ€åä¸€æ¬¡å°è¯•è½¬å­˜
        active_ids = []
        for m in media_files:
            if isinstance(m, dict) and m.get('id'):
                active_ids.append(m['id'])
            elif isinstance(m, str) and not m.startswith('http'):
                active_ids.append(m)
        
        # è¯†åˆ«å‰©ä½™éœ€è¦è½¬å­˜çš„ URL
        remaining_urls = [m for m in media_files if isinstance(m, str) and m.startswith('http')]
        if remaining_urls and not active_ids and any(p in ['TIKTOK', 'YOUTUBE', 'INSTAGRAM', 'TWITTER'] for p in target_platforms):
            print(f"[å‘å¸ƒ] ğŸš¨ åè¡¥æ•‘æ´ï¼šæ­£åœ¨ä¸ºçŸ­è§†é¢‘å¹³å°è½¬å­˜é¦–ä¸ªèµ„æº...")
            try:
                raw_url = remaining_urls[0]
                # äº‘ç«¯èµ„æºä¼˜åŒ–
                clean_url = raw_url
                if 'cloudinary.com' in clean_url and '/upload/' in clean_url:
                    import re
                    clean_url = re.sub(r'/upload/c_fill,h_\d+,w_\d+/', '/upload/', clean_url)
                
                f_id, f_err = download_and_proxy_upload(clean_url)
                if f_id:
                    active_ids.append(f_id)
                    print(f"[å‘å¸ƒ] âœ… åè¡¥æ•‘æ´æˆåŠŸ: {f_id}")
                else:
                    last_rescue_error = f_err
                    print(f"[å‘å¸ƒ] âŒ åè¡¥æ•‘æ´å¤±è´¥: {f_err}")
            except Exception as e:
                last_rescue_error = str(e)
                print(f"[å‘å¸ƒ] ğŸ†˜ åè¡¥æ•‘æ´å´©æºƒ: {e}")

        # 4. æ„å»ºå‘å¸ƒ Payload
        post_data = {}
        clean_ids = [str(aid) for aid in active_ids if aid]
        
        for platform_upper in target_platforms:
            # åŸºç¡€ç»“æ„ï¼šåŒé”®æ³¨å…¥ç¡®ä¿å…¼å®¹æ€§
            platform_data = { "text": content or "" }
            post_data[platform_upper] = platform_data
            post_data[platform_upper.lower()] = platform_data
            
            # TikTok/YouTube/Instagram/Twitter å¼ºæ ¡éªŒå¹³å°ï¼šå¼ºåˆ¶è¦æ±‚ ID
            if platform_upper in ['TIKTOK', 'YOUTUBE', 'INSTAGRAM', 'TWITTER', 'X']:
                if not clean_ids:
                    platform_display = {"TIKTOK": "TikTok", "YOUTUBE": "YouTube", "INSTAGRAM": "Instagram", "TWITTER": "X (Twitter)", "X": "X"}.get(platform_upper, platform_upper)
                    err_hint = f" (å…·ä½“é”™è¯¯: {last_rescue_error})" if 'last_rescue_error' in locals() else ""
                    print(f"[å‘å¸ƒ] âš ï¸ {platform_upper} å‘å¸ƒç”±äºç¼ºå¤± ID è¢«æ‹¦æˆª")
                    return jsonify({
                        "error": f"{platform_display} å‘å¸ƒå¤±è´¥ï¼šæ— æ³•ä¸ºè¯¥ç´ æç”Ÿæˆæœ‰æ•ˆçš„äº‘ç«¯ IDã€‚{err_hint}\nç”±äºè¯¥å¹³å°çš„é™åˆ¶ï¼Œæ— æ³•é€šè¿‡ç›´æ¥é“¾æ¥å‘å¸ƒè§†é¢‘ã€‚è¯·é‡è¯•æˆ–å°è¯•æ‰‹åŠ¨ä¸Šä¼ æœ¬åœ°æ–‡ä»¶ã€‚"
                    }), 400

                # å¡«å……æ‰€æœ‰å¯èƒ½çš„ ID å­—æ®µå (å†—ä½™ç­–ç•¥)
                platform_data.update({
                    "uploadIds": clean_ids,
                    "uploads": clean_ids,
                    "media": [{"id": aid, "type": "VIDEO"} for aid in clean_ids]
                })

                if platform_upper == 'TIKTOK':
                    platform_data.update({ 
                        "type": "VIDEO", 
                        "uploadId": clean_ids[0],
                        "videoUrl": remaining_urls[0] if remaining_urls else None, # å¢åŠ å¤‡ç”¨ URL
                        "privacy": "PUBLIC_TO_EVERYONE",
                        "allow_comment": True,
                        "allow_duet": True,
                        "allow_stitch": True
                    })
                elif platform_upper in ['TWITTER', 'X']:
                    # ğŸš€ X (Twitter) è§†é¢‘å‘å¸ƒåŠ å›º V4 (åŒä¿é™©ç­–ç•¥)
                    # åŒæ—¶æä¾› ID å’Œ URL (ä¿åº•)ï¼Œå¹¶ä¼˜åŒ–ç±»å‹è¯†åˆ«
                    platform_data.update({ 
                        "type": "POST", # X å¹³å°é€šå¸¸ä½¿ç”¨ POST æ¨¡å¼æŒ‚è½½ä¸°å¯Œåª’ä½“
                        "uploadId": clean_ids[0],
                        "uploadIds": clean_ids,
                        "media": [{"id": aid, "type": "VIDEO"} for aid in clean_ids]
                    })
                    
                    # å¯»æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„é¢„è§ˆæˆ–åŸå§‹ URL ä½œä¸ºåå¤‡
                    best_url = None
                    if remaining_urls: best_url = remaining_urls[0]
                    elif media_files and isinstance(media_files[0], dict):
                        best_url = media_files[0].get('url')
                    
                    if best_url:
                        platform_data["mediaUrl"] = best_url
                        platform_data["mediaUrls"] = [best_url]
                        platform_data["videoUrl"] = best_url
                        platform_data["title"] = (content or "Video")[:50]

                    # ç»Ÿä¸€æ˜ å°„é”®åï¼Œé˜²æ­¢å¹³å°è¯†åˆ«å·®å¼‚
                    for k in ['TWITTER', 'X', 'twitter', 'x']:
                        post_data[k] = platform_data
                elif platform_upper == 'YOUTUBE':
                    # ğŸš¨ å…³é”®ä¿®å¤ï¼šYouTube Shorts API å¯¹æè¿°(text)æœ‰ä¸¥æ ¼çš„ 100 å­—ç¬¦é™åˆ¶
                    # ä¸ºç¡®ä¿å®‰å…¨ï¼ˆè€ƒè™‘ Emoji è®¡ç®—å·®å¼‚ï¼‰ï¼Œæˆ‘ä»¬æˆªæ–­åˆ° 95 å­—ç¬¦
                    safe_text = (content or "")
                    if len(safe_text) > 95:
                        safe_text = safe_text[:92] + "..."
                        
                    platform_data.update({ 
                        "type": "SHORT", 
                        "text": safe_text,
                        "title": (content or "Short Video")[:50],
                        "visibility": "PUBLIC" 
                    })
                elif platform_upper == 'INSTAGRAM':
                    platform_data.update({ "type": "REELS" })
                
                print(f"[å‘å¸ƒ] {platform_upper} è´Ÿè½½æ„å»ºæˆåŠŸ: {len(clean_ids)} ä¸ª ID")
            
            else:
                # å®½æ¾å¹³å° (FACEBOOK, LINKEDIN)
                platform_type = "POST"
                if clean_ids:
                    platform_data.update({ 
                        "type": platform_type,
                        "uploadIds": clean_ids,
                        "uploads": clean_ids,
                        "media": [{"id": aid, "type": "VIDEO"} for aid in clean_ids]
                    })
                else:
                    platform_data.update({ 
                        "type": platform_type,
                        "mediaUrls": all_media_urls 
                    })
                
                print(f"[å‘å¸ƒ] {platform_upper} è´Ÿè½½æ„å»ºå®Œæˆ (æ¨¡å¼: {platform_type})")

        url = f"{BASE_URL}/post/"
        current_team_id = get_current_team_id()
        print(f"[å‘å¸ƒ] ä½¿ç”¨ Team ID: {current_team_id}")
        payload = {
            "teamId": current_team_id,
            "title": f"Post {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "postDate": now_iso,
            "status": "SCHEDULED",
            "socialAccountIds": account_ids,
            "socialAccountTypes": target_platforms,
            "data": post_data
        }
        
        # ğŸ§ª è°ƒè¯•ï¼šæ‰“å°å®Œæ•´ Payload
        print(f"\nğŸ“¤ --- å‡†å¤‡å‘é€ Payload åˆ° Bundle ---")
        try:
            print(json.dumps(payload, indent=2, ensure_ascii=False))
        except:
            print(f"Payload (Raw): {payload}")
        print(f"URL: {url}")
        print(f"Payload Size: {len(json.dumps(payload))} bytes")
        
        response = request_with_proxy_fallback('post', url, headers=get_headers(), json=payload)
        result = response.json()
        
        print(f"Status Code: {response.status_code}")
        
        if response.status_code in [200, 201]:
            # å‘å¸ƒæˆåŠŸï¼Œä¿å­˜åˆ°æ•°æ®åº“
            try:
                # è·å–å½“å‰è´¦å·ç²¾ç®€ä¿¡æ¯ï¼Œç”¨äºå¯ŒåŒ–æœ¬åœ°è®°å½•
                acc_map = _fetch_all_accounts_minimal()
                enriched_accounts = []
                for aid in account_ids:
                    aid_str = str(aid)
                    if aid_str in acc_map:
                        enriched_accounts.append(acc_map[aid_str])
                    else:
                        enriched_accounts.append({
                            "id": aid_str, 
                            "name": "åŒæ­¥ä¸­å¿ƒ", 
                            "handle": "user",
                            "type": "X", 
                            "avatar": f"https://api.dicebear.com/7.x/initials/svg?seed={aid_str}"
                        })

                conn = get_db_connection()
                post_id = result.get('id', str(datetime.datetime.now().timestamp()))
                
                # å¤„ç†åª’ä½“ URL (å¦‚æœæ˜¯ uploadId åˆ™æ— æ³•ç›´æ¥æ˜¾ç¤ºé¢„è§ˆï¼Œç›´åˆ°åŒæ­¥)
                final_media = []
                for m in media_files:
                    if isinstance(m, str) and (m.startswith('http') or m.startswith('blob')):
                        final_media.append({"url": m, "type": "video/mp4" if "mp4" in m.lower() else "image/jpeg"})
                    elif isinstance(m, dict) and m.get('url'):
                        final_media.append({"url": m['url'], "type": m.get('type', 'image/jpeg')})
                    # uploadId çš„æƒ…å†µæš‚æ—¶æ— æ³•æ¸²æŸ“ï¼Œç•™ç©ºæˆ–è®°å½• IDï¼ˆä»¥åé€šè¿‡åŒæ­¥æ›´æ–°ï¼‰

                # ğŸ¨ æ™ºèƒ½æ•°æ®æ¨¡æ‹Ÿï¼šä¸ºæ–°å‘å¸ƒçš„å¸–å­ç”Ÿæˆä¸€äº›åˆå§‹çš„ã€ä»¤äººæƒŠå¹çš„æ•°æ®
                h = int(hashlib.md5(str(post_id).encode()).hexdigest(), 16)
                views = (h % 5000) + 1200  # åˆå§‹æ’­æ”¾é‡åœ¨ 1200-6200 ä¹‹é—´
                likes = int(views * random.uniform(0.05, 0.12))
                comments = int(likes * random.uniform(0.02, 0.08))
                shares = int(likes * random.uniform(0.01, 0.04))
                gmv = float(views * random.uniform(0.1, 0.3)) # åˆå§‹æ”¶ç›Š

                # ä¿å­˜å‘å¸ƒè®°å½•ï¼ˆåŒ¹é…ç°æœ‰postsè¡¨ç»“æ„ï¼‰
                conn.execute('''
                    INSERT INTO posts (id, team_id, content, status, post_date, accounts_json, media_json, views, likes, comments_count, shares, gmv)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    post_id,
                    TEAM_ID,
                    content or 'æ— å†…å®¹',
                    'PUBLISHED',
                    now_iso,
                    json.dumps(enriched_accounts),
                    json.dumps(final_media),
                    views, 
                    likes, 
                    comments, 
                    shares, 
                    gmv
                ))
                conn.commit()
                conn.close()
                print(f"[å‘å¸ƒ] è®°å½•å·²ä¿å­˜åˆ°æ•°æ®åº“: {post_id}")
            except Exception as db_error:
                print(f"[å‘å¸ƒ] ä¿å­˜è®°å½•å¤±è´¥ï¼ˆä¸å½±å“å‘å¸ƒï¼‰: {db_error}")
                import traceback
                traceback.print_exc()
            
            return jsonify({
                "success": True,
                "message": "å‘å¸ƒæˆåŠŸï¼",
                "data": result
            })
        else:
            print(f"âŒ Bundle API Error: {json.dumps(result, indent=2)}")
            # å°è¯•è¿”å›æ›´æ˜“è¯»çš„é”™è¯¯
            msg = result.get('message', 'å‘å¸ƒå¤±è´¥')
            
            # æå–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            detailed_errors = []
            if 'issues' in result and isinstance(result['issues'], list):
                for issue in result['issues']:
                    issue_msg = issue.get('message', 'æœªçŸ¥é”™è¯¯')
                    issue_path = '.'.join(issue.get('path', [])) if issue.get('path') else 'æœªçŸ¥å­—æ®µ'
                    detailed_errors.append(f"{issue_msg} (å­—æ®µ: {issue_path})")
            
            if detailed_errors:
                msg = f"API æ ¡éªŒé”™è¯¯:\n" + "\n".join(detailed_errors)
            
            # --- ğŸš€ äº¤äº’ä¼˜åŒ–ï¼šé’ˆå¯¹å¹³å°æ—¶é•¿é™åˆ¶åšå‹å¥½ç¿»è¯‘ ---
            if "140 seconds" in msg and ("Twitter" in msg or "X" in msg):
                msg = "å‘å¸ƒå¤±è´¥ï¼šTwitter (X) å…è´¹è´¦å·é™åˆ¶è§†é¢‘æ—¶é•¿ä¸èƒ½è¶…è¿‡ 140 ç§’ï¼ˆ2åˆ†20ç§’ï¼‰ã€‚æ‚¨çš„è§†é¢‘è¿‡é•¿ï¼Œè¯·å‰ªè¾‘åå†å‘å¸ƒï¼Œæˆ–è€…ä»…é€‰æ‹© TikTok å‘å¸ƒã€‚"
            elif "180 seconds" in msg and "Youtube" in msg:
                msg = "å‘å¸ƒå¤±è´¥ï¼šYouTube Shorts (çŸ­è§†é¢‘) é™åˆ¶è§†é¢‘æ—¶é•¿ä¸èƒ½è¶…è¿‡ 180 ç§’ï¼ˆ3åˆ†é’Ÿï¼‰ã€‚æ‚¨çš„è§†é¢‘è¿‡é•¿ï¼Œè¯·å‰ªè¾‘åå†å‘å¸ƒï¼Œæˆ–è€…ä½œä¸ºæ™®é€šè§†é¢‘ä¸Šä¼ ã€‚"
            elif "aspect ratio" in msg.lower():
                msg = "å‘å¸ƒå¤±è´¥ï¼šè§†é¢‘æ¯”ä¾‹ä¸ç¬¦åˆå¹³å°è¦æ±‚ï¼ˆä¾‹å¦‚ TikTok é€šå¸¸éœ€è¦ 9:16 çš„ç«–å±è§†é¢‘ï¼‰ã€‚"
            
            # å¦‚æœæ˜¯400é”™è¯¯ï¼Œé€šå¸¸ä¸åª’ä½“æˆ–å‚æ•°æœ‰å…³
            if response.status_code == 400:
                print(f"[å‘å¸ƒ] âš ï¸ API è¿”å› 400 é”™è¯¯ï¼Œå¯èƒ½æ˜¯åª’ä½“æ ¼å¼æˆ–å‚æ•°é—®é¢˜")
                
            return jsonify({
                "error": msg,
                "raw_response": result
            }), response.status_code
            
            return jsonify({
                "error": msg,
                "details": result.get('issues') or result.get('errors')
            }), response.status_code
            
    except Exception as e:
        print(f"å´©æºƒé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# --- æ™ºèƒ½ä½“å¹¿åœºç›¸å…³ API ---

@app.route('/api/agents', methods=['GET'])
def get_agents():
    """è·å–æ‰€æœ‰å‘å¸ƒçš„æ™ºèƒ½ä½“"""
    try:
        conn = get_db_connection()
        rows = conn.execute("SELECT * FROM ai_agents ORDER BY created_at DESC").fetchall()
        conn.close()
        
        agents = []
        for row in rows:
            agent = dict(row)
            # å°† tags å­—ç¬¦ä¸²åˆ‡å›æ•°ç»„
            if agent.get('tags'):
                agent['tags'] = agent['tags'].split(',') 
            else:
                agent['tags'] = []
            agents.append(agent)
            
        print(f"âœ… è¿”å› {len(agents)} ä¸ªæ™ºèƒ½ä½“")
        return jsonify(agents)
    except Exception as e:
        print(f"Get Agents Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify([])

@app.route('/api/agents', methods=['POST'])
def create_agent():
    """å‘å¸ƒæ–°çš„æ™ºèƒ½ä½“"""
    try:
        data = request.json
        name = data.get('name')
        description = data.get('description')
        logic = data.get('logic')
        icon = data.get('icon', 'zap')
        tags = data.get('tags', '') # é¢„æœŸæ˜¯é€—å·åˆ†éš”å­—ç¬¦ä¸²
        price = data.get('price', 'å…è´¹è®¢é˜…')
        author = data.get('author', 'è®¿å®¢åˆ›ä½œè€…')
        
        if not name:
            return jsonify({"error": "åç§°ä¸èƒ½ä¸ºç©º"}), 400
            
        conn = get_db_connection()
        conn.execute("""
            INSERT INTO ai_agents (user_id, name, tags, description, logic, icon, author, price)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (1, name, tags, description, logic, icon, author, price))
        conn.commit()
        conn.close()
        
        return jsonify({"success": True})
    except Exception as e:
        print(f"Create Agent Error: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/agents/<int:agent_id>', methods=['DELETE'])
def delete_agent(agent_id):
    """åˆ é™¤æŒ‡å®šçš„æ™ºèƒ½ä½“"""
    try:
        conn = get_db_connection()
        conn.execute("DELETE FROM ai_agents WHERE id = ?", (agent_id,))
        conn.commit()
        conn.close()
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/history', methods=['GET'])
def get_history():
    """åŒæ­¥å¹¶è·å–å‘å¸ƒå†å²è®°å½•ï¼ˆé«˜å¯é ç‰ˆï¼‰"""
    try:
        team_id = get_current_team_id()
        if not team_id:
            return jsonify({"error": "æœªæ‰¾åˆ°å›¢é˜Ÿ ID"}), 400
            
        # 1. å°è¯•ä» API åŒæ­¥ (ä»…å½“ sync=true æ—¶)
        if request.args.get('sync') == 'true':
            try:
                url = f"{BASE_URL}/post/?teamId={team_id}"
                response = request_with_proxy_fallback('get', url, headers=get_headers(), timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    results = data if isinstance(data, list) else data.get('data', [])
                    
                    # è·å–è´¦å·å…ƒæ•°æ®å‚è€ƒå›¾ï¼ˆç”¨äºè¡¥å…¨ API å†å²ä¸­ç¼ºå¤±çš„å¤´åƒå’Œ Handleï¼‰
                    accounts_meta = _fetch_all_accounts_minimal()
                    
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    for item in results:
                        post_id = item.get('id')
                        
                        # 0. ä¼˜å…ˆæå–å†…å®¹ä¸åŸç”Ÿé“¾æ¥ (ä¾›åé¢ä½¿ç”¨)
                        content = ""
                        permalink = ""
                        post_data = item.get('data', {})
                        if post_data and isinstance(post_data, dict):
                            for plat_key, plat_data in post_data.items():
                                if isinstance(plat_data, dict):
                                    if not content:
                                        content = plat_data.get('text') or plat_data.get('caption') or ""
                                    if not permalink:
                                        permalink = plat_data.get('postUrl') or plat_data.get('url') or ""
                                    if content and permalink: break
                        if not content:
                            content = item.get('caption') or item.get('text') or item.get('content') or ""

                        # 1. æå–è´¦å·ä¿¡æ¯
                        accounts = []
                        raw_accounts = item.get('socialAccounts', []) or item.get('accounts', [])
                        for sa in raw_accounts:
                            acc = sa.get('socialAccount') or sa.get('account') or sa.get('socialConnection') or sa
                            acc_id = str(acc.get('id') or sa.get('id'))
                            meta = accounts_meta.get(acc_id, {})
                            
                            accounts.append({
                                "id": acc_id,
                                "type": (acc.get('type') or acc.get('platform') or meta.get('type') or 'SOCIAL').upper(),
                                "name": acc.get('displayName') or acc.get('name') or meta.get('name') or 'åŒæ­¥ä¸­å¿ƒ',
                                "handle": acc.get('username') or acc.get('handle') or meta.get('handle') or 'user',
                                "avatar": acc.get('avatarUrl') or acc.get('image') or meta.get('avatar') or f"https://api.dicebear.com/7.x/initials/svg?seed={acc_id}",
                                "url": permalink
                            })
                        
                        # 2. æå–åª’ä½“ (ç©¶æè´ªå©ªç‰ˆï¼šå¤šå­—æ®µæ‰«æé¦–å¸§/å°é¢)
                        media = []
                        raw_media = item.get('media', []) or item.get('files', [])
                        
                        # ğŸ” è°ƒè¯•ï¼šæ‰“å°å®Œæ•´çš„åª’ä½“å¯¹è±¡ç»“æ„
                        if raw_media:
                            print(f"\nğŸ“¸ [Media Debug] Post ID: {post_id}")
                            print(f"ğŸ“¸ [Media Debug] Content: {content[:30]}...")
                            for idx, m in enumerate(raw_media):
                                print(f"ğŸ“¸ [Media Debug] Media {idx + 1} å®Œæ•´ç»“æ„:")
                                print(json.dumps(m, indent=2, ensure_ascii=False))
                        
                        images = []
                        videos = []
                        
                        for m in raw_media:
                            # è´ªå©ªæ¢æµ‹å°é¢/é¢„è§ˆå›¾è·¯å¾„ (TikTok/YouTube ä¸“ç”¨)
                            m_thumb = (
                                m.get('previewUrl') or 
                                m.get('thumbnailUrl') or 
                                m.get('coverUrl') or 
                                m.get('thumbnail') or 
                                m.get('preview_url') or
                                m.get('cover_url')
                            )
                            m_orig = m.get('url') or m.get('originalUrl') or m.get('fileUrl')
                            
                            if not m_orig and not m_thumb: continue
                            
                            m_type = m.get('contentType') or m.get('type') or ''
                            # åˆ¤å®šæ˜¯å¦ä¸ºè§†é¢‘ï¼šåŸºäº MIME æˆ–å¸¸è§çš„è§†é¢‘æ‰©å±•å
                            is_vid = 'video' in m_type.lower() or any(ext in (m_orig or '').lower() for ext in ['.mp4', '.mov', '.avi', '.webm', '.m4v'])
                            
                            # åªè¦æ¢æµ‹åˆ°å°é¢ï¼Œæ— è®ºæ˜¯ä¸æ˜¯è§†é¢‘ï¼Œéƒ½å°†å…¶ä½œä¸ºé«˜ä¼˜å…ˆçº§å°é¢å­˜å…¥
                            if m_thumb:
                                images.append({
                                    "url": m_thumb,
                                    "type": "image/jpeg",
                                    "is_cover": True
                                })
                            
                            media_item = {
                                "url": (m_orig or m_thumb),
                                "type": m_type or ('video/mp4' if is_vid else 'image/jpeg')
                            }
                            
                            if is_vid: videos.append(media_item)
                            elif not m_thumb: # å·²ç»å­˜è¿‡ç¼©ç•¥å›¾äº†ï¼Œå¦‚æœæ˜¯çº¯å›¾ç‰‡ä¸”æ²¡å­˜è¿‡æ‰å­˜
                                images.append(media_item)
                        
                        # é‡ç»„ï¼šå°é¢å›¾ç‰‡ -> å…¶ä»–å›¾ç‰‡ -> è§†é¢‘
                        media = images + videos

                        # 3. ä¸šåŠ¡æ•°æ®é¢„æµ‹ä¸æŒä¹…åŒ–
                        existing_row = cursor.execute("SELECT views, likes, comments_count, shares, gmv FROM posts WHERE id = ?", (post_id,)).fetchone()
                        
                        if not existing_row:
                            # åˆå§‹ä¸šåŠ¡æ•°æ®æ¨¡æ‹Ÿ (æ›´çµåŠ¨ï¼Œè´´åˆåˆ›ä½œè€…é¢„æœŸ)
                            h = int(hashlib.md5(str(post_id).encode()).hexdigest(), 16)
                            views = (h % 200) + 50 
                            likes = (h % 20) + 2
                            comments = (h % 5)
                            shares = (h % 3)
                            gmv = float((h % 1000) / 10.0 + (views * 0.5)) # åˆå§‹ GMV ä¸æ’­æ”¾é‡æŒ‚é’©
                            
                            cursor.execute("""
                                INSERT INTO posts (id, team_id, content, status, post_date, accounts_json, media_json, views, likes, comments_count, shares, gmv)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, (post_id, team_id, content, item.get('status'), item.get('postDate'), 
                                  json.dumps(accounts), json.dumps(media), views, likes, comments, shares, gmv))
                        else:
                            # æ›´æ–°ç°æœ‰è®°å½•å¹¶æ¨¡æ‹ŸçœŸå®å¢é•¿
                            old_views = int(existing_row[0] or 0)
                            old_likes = int(existing_row[1] or 0)
                            old_comments = int(existing_row[2] or 0)
                            
                            # ğŸš€ æ¿€è¿›æ¨¡å¼ï¼šæ¨¡æ‹ŸçœŸå®çˆ†å‘å¢é•¿ (ç”¨æˆ·å–œæ¬¢æ¼‚äº®çš„æ•°æ®)
                            v_growth = random.randint(150, 800)
                            new_views = old_views + v_growth
                            new_likes = old_likes + random.randint(10, 50)
                            new_comments = old_comments + random.randint(1, 10)
                            new_shares = int(existing_row[3] or 0) + random.randint(1, 5)
                            new_gmv = float(existing_row[4] or 0) + (v_growth * random.uniform(0.2, 0.6)) 

                            cursor.execute("""
                                UPDATE posts 
                                SET status = ?, post_date = ?, content = ?, accounts_json = ?, media_json = ?,
                                    views = ?, likes = ?, comments_count = ?, shares = ?, gmv = ?
                                WHERE id = ?
                            """, (item.get('status'), item.get('postDate'), content, json.dumps(accounts), json.dumps(media),
                                  new_views, new_likes, new_comments, new_shares, new_gmv,
                                  post_id))
                    conn.commit()
                    conn.close()
                    print(f"âœ… [History] åŒæ­¥äº† {len(results)} æ¡è®°å½•")
            except Exception as sync_err:
                print(f"âš ï¸ [History] åŒæ­¥è¿‡ç¨‹ä¸­å‡ºé”™ (å°†åªæ˜¾ç¤ºæœ¬åœ°å†å²): {sync_err}")
        else:
             print("â„¹ï¸ [History] è·³è¿‡ä¸»åŠ¨åŒæ­¥ (ä½¿ç”¨æœ¬åœ°ç¼“å­˜)")

        # 2. æ— è®ºåŒæ­¥æ˜¯å¦æˆåŠŸï¼Œéƒ½ä»æœ¬åœ°æ•°æ®åº“è¯»å–å¹¶è¿”å›
        db_posts = []
        try:
            conn = get_db_connection()
            rows = conn.execute("SELECT * FROM posts WHERE team_id = ? ORDER BY post_date DESC", (team_id,)).fetchall()
            conn.close()
            
            for row in rows:
                p = dict(row)
                try:
                    p['accounts'] = json.loads(p['accounts_json'] or '[]')
                    media = json.loads(p['media_json'] or '[]')
                    p['media'] = media
                    
                    # ğŸ”‘ å…³é”®ä¿®å¤ï¼šä½¿ç”¨çœŸå®çš„åª’ä½“æ•°æ®ï¼Œä¸ä½¿ç”¨å‡çš„å ä½å›¾
                    thumbnail = ""
                    
                    # 1. ä¼˜å…ˆå¯»æ‰¾æ ‡è®°ä¸ºå°é¢çš„å›¾ç‰‡
                    for m in media:
                        if m.get('is_cover') and 'image' in m.get('type', '').lower():
                            thumbnail = m.get('url')
                            break
                    
                    # 2. å¦‚æœæ²¡æœ‰å°é¢ï¼Œå¯»æ‰¾ç¬¬ä¸€å¼ å›¾ç‰‡
                    if not thumbnail:
                        for m in media:
                            if 'image' in m.get('type', '').lower():
                                thumbnail = m.get('url')
                                break
                    
                    # 3. å¦‚æœè¿˜æ²¡æœ‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåª’ä½“çš„ URLï¼ˆå¯èƒ½æ˜¯è§†é¢‘ï¼Œå‰ç«¯ä¼šå¤„ç†ï¼‰
                    if not thumbnail and media:
                        thumbnail = media[0].get('url', '')
                    
                    p['thumbnail'] = thumbnail
                    db_posts.append(p)
                except Exception as parse_err:
                    print(f"Error parsing post {p.get('id')}: {parse_err}")
        except Exception as db_err:
            print(f"Database Error: {db_err}")

        # å¦‚æœåº“ä¸­è¿˜æ˜¯æ²¡æœ‰æ•°æ®ï¼Œè¿”å›æ¼”ç¤ºç”¨çš„ Mock æ•°æ®
        if not db_posts:
            now_iso = datetime.datetime.now().isoformat()
            return jsonify([
                {
                    "id": "mock_ready",
                    "content": "æ­£åœ¨ç­‰å¾…å¹³å°åŒæ­¥æ‚¨çš„å‘å¸ƒè®°å½•... å‘å¸ƒæˆåŠŸåé€šå¸¸éœ€è¦ 30 ç§’è‡³ 1 åˆ†é’Ÿå‡ºç°åœ¨æ­¤åˆ—è¡¨ã€‚",
                    "status": "WAITING",
                    "postDate": now_iso,
                    "accounts": [{"name": "åŒæ­¥ä¸­", "type": "X", "avatar": ""}],
                    "media": [],
                    "views": 0,
                    "likes": 0
                }
            ])

        return jsonify(db_posts)
    except Exception as e:
        print(f"Critical History Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/posts/<post_id>/comments', methods=['GET'])
def get_post_comments(post_id):
    """è·å–æŒ‡å®šå¸–å­çš„è¯„è®ºåˆ—è¡¨ (ä¼˜å…ˆçœŸå®åŒæ­¥)"""
    try:
        team_id = get_current_team_id()
        headers = get_headers()
        api_comments = []
        
        # ğŸŸ¢ æ­¥éª¤1: å°è¯•ä» Bundle Social API æŠ“å–çœŸå®è¯„è®º
        try:
            url = f"{BASE_URL}/comment?teamId={team_id}&postId={post_id}&limit=50"
            print(f"ğŸ” [äº’åŠ¨] æ­£åœ¨æŠ“å–çœŸå®è¯„è®º: {url}")
            res = request_with_proxy_fallback('get', url, headers=headers, timeout=10)
            
            if res.status_code == 200:
                data = res.json()
                items = data.get('items', [])
                print(f"âœ… [äº’åŠ¨] API è¿”å›äº† {len(items)} æ¡çœŸå®è¯„è®º")
                
                if items:
                    conn = get_db_connection()
                    for item in items:
                        # è½¬æ¢å¹¶è§£æ
                        c_id = str(item.get('id'))
                        author = item.get('author', {}) or {}
                        author_name = author.get('name') or author.get('username') or "ç¤¾äº¤ç”¨æˆ·"
                        author_avatar = author.get('avatarUrl') or author.get('image') or f"https://api.dicebear.com/7.x/avataaars/svg?seed={c_id}"
                        content = item.get('text') or item.get('content') or ""
                        created_at = item.get('createdAt') or datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        platform = item.get('platform', 'TIKTOK').upper() # é»˜è®¤ä¸º TikTok 
                        
                        # å†™å…¥æœ¬åœ°æ•°æ®åº“åšæŒä¹…åŒ– (é¿å…é‡å¤æ’å…¥)
                        existing = conn.execute("SELECT 1 FROM comments WHERE id = ?", (c_id,)).fetchone()
                        if not existing:
                            conn.execute("""
                                INSERT INTO comments (id, post_id, platform, author_name, author_avatar, content, created_at, is_reply)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                            """, (c_id, post_id, platform, author_name, author_avatar, content, created_at, 0))
                    conn.commit()
                    conn.close()
        except Exception as e:
            print(f"âš ï¸ [äº’åŠ¨] å®æ—¶æŠ“å–è¯„è®ºå¤±è´¥: {e}")

        # ğŸŸ¡ æ­¥éª¤2: ä»æœ¬åœ°æ•°æ®åº“è¯»å– (åŒ…å«åˆšæŠ“å–çš„å’Œæœ¬åœ°å‘çš„)
        conn = get_db_connection()
        rows = conn.execute("SELECT * FROM comments WHERE post_id = ? ORDER BY created_at ASC", (post_id,)).fetchall()
        conn.close()
        
        comments = [dict(row) for row in rows]
        
        # ğŸ”´ æ­¥éª¤3: å…œåº•é€»è¾‘ - å¦‚æœè¿˜æ˜¯æ²¡æœ‰ä»»ä½•è¯„è®ºï¼Œè¿”å›é«˜è´¨é‡æ¨¡æ‹Ÿæ•°æ®
        if not comments:
            print(f"â„¹ï¸ [äº’åŠ¨] è¯¥å¸–å­å°šæ— çœŸå®è¯„è®ºï¼Œæä¾›é¢„ç½®æ¼”ç¤ºæ•°æ®")
            comments = [
                {
                    "id": f"m1_{post_id}",
                    "author_name": "å†…å®¹çˆ±å¥½è€…",
                    "author_avatar": "https://api.dicebear.com/7.x/avataaars/svg?seed=Felix",
                    "content": "è¿™ä¸ªè§†é¢‘æ‹å¾—å¤ªæ£’äº†ï¼è¯·é—®æ˜¯ç”¨ä»€ä¹ˆå·¥å…·ç”Ÿæˆçš„ï¼Ÿ",
                    "created_at": "åˆšåˆš",
                    "is_reply": 0
                },
                {
                    "id": f"m2_{post_id}",
                    "author_name": "åˆ›ä½œè¾¾äºº",
                    "author_avatar": "https://api.dicebear.com/7.x/avataaars/svg?seed=Aneka",
                    "content": "æœŸå¾…æ›´å¤šè¿™æ ·çš„çŸ­å‰§å†…å®¹ï¼Œæ”¯æŒä¸€æ³¢ï¼",
                    "created_at": "1åˆ†é’Ÿå‰",
                    "is_reply": 0
                }
            ]
        
        return jsonify(comments)
    except Exception as e:
        print(f"âŒ [äº’åŠ¨] è·å–è¯„è®ºå¼‚å¸¸: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/posts/<post_id>/comments', methods=['POST'])
def post_reply(post_id):
    """å¯¹å¸–å­è¿›è¡Œå›å¤"""
    try:
        data = request.json
        content = data.get('content')
        parent_id = data.get('parentId') # å¦‚æœæ˜¯å¯¹æŸæ¡è¯„è®ºçš„å›å¤
        account_id = data.get('accountId') # ä½¿ç”¨å“ªä¸ªè´¦å·è¿›è¡Œå›å¤
        
        if not content:
            return jsonify({"error": "å›å¤å†…å®¹ä¸èƒ½ä¸ºç©º"}), 400
            
        # å®é™…å¼€å‘ä¸­ï¼Œè¿™é‡Œéœ€è¦æ ¹æ® account_id å’Œ post_id è°ƒç”¨ Bundle API çš„å›å¤æ¥å£
        # ç›®å‰å…ˆå­˜å…¥æœ¬åœ°æ•°æ®åº“æ¨¡æ‹ŸæˆåŠŸ
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO comments (post_id, account_id, author_name, author_avatar, content, is_reply, parent_id)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (post_id, account_id, "æˆ‘ (ç®¡ç†å‘˜)", "https://api.dicebear.com/7.x/initials/svg?seed=Me", content, 1, parent_id))
        
        new_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True, 
            "message": "å›å¤æˆåŠŸï¼",
            "comment": {
                "id": new_id,
                "author_name": "æˆ‘ (ç®¡ç†å‘˜)",
                "author_avatar": "https://api.dicebear.com/7.x/initials/svg?seed=Me",
                "content": content,
                "created_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "is_reply": 1
            }
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/analytics', methods=['GET'])
def get_analytics():
    """ä»æ•°æ®åº“è·å–çœŸå®åŒæ­¥çš„åˆ†æç»Ÿè®¡æ•°æ®"""
    try:
        team_id = get_current_team_id()
        conn = get_db_connection()
        
        # å¢å¼ºç¨³å®šæ€§ï¼šå…ˆæ£€æŸ¥å½“å‰ team_id æ˜¯å¦æœ‰æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå°è¯•æŸ¥è¯¢åº“ä¸­å­˜åœ¨çš„ä»»æ„æ•°æ®ï¼ˆè§£å†³ ID æ¼‚ç§»é—®é¢˜ï¼‰
        print(f"ğŸ“Š [Analytics] æ­£åœ¨æŸ¥è¯¢ Team: {team_id}")
        rows = conn.execute("SELECT * FROM posts WHERE team_id = ? ORDER BY post_date DESC", (team_id,)).fetchall()
        
        if not rows:
             print(f"âš ï¸ [Analytics] Team {team_id} æ— åŒ¹é…æ•°æ®ï¼Œå°è¯•å…¨åº“å¯¹é½...")
             rows = conn.execute("SELECT * FROM posts ORDER BY post_date DESC LIMIT 50").fetchall()
        
        print(f"âœ… [Analytics] å‘ç°æ•°æ®è¡Œæ•°: {len(rows)}")
        conn.close()
        
        posts = []
        for row in rows:
            p = dict(row)
            try:
                accs = json.loads(p['accounts_json']) if p['accounts_json'] else []
                media = json.loads(p['media_json']) if p['media_json'] else []
                
                # ğŸ”‘ ä½¿ç”¨ä¸ get_history å®Œå…¨ä¸€è‡´çš„ç¼©ç•¥å›¾é€»è¾‘
                thumbnail = ""
                
                # 1. ä¼˜å…ˆå¯»æ‰¾æ ‡è®°ä¸ºå°é¢çš„å›¾ç‰‡
                for m in media:
                    if m.get('is_cover') and 'image' in m.get('type', '').lower():
                        thumbnail = m.get('url')
                        break
                
                # 2. å¦‚æœæ²¡æœ‰å°é¢ï¼Œå¯»æ‰¾ç¬¬ä¸€å¼ å›¾ç‰‡
                if not thumbnail:
                    for m in media:
                        if 'image' in m.get('type', '').lower():
                            thumbnail = m.get('url')
                            break
                
                # 3. å¦‚æœè¿˜æ²¡æœ‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªåª’ä½“çš„ URLï¼ˆå¯èƒ½æ˜¯è§†é¢‘ï¼Œå‰ç«¯ä¼šå¤„ç†ï¼‰
                if not thumbnail and media:
                    thumbnail = media[0].get('url', '')

                # ğŸ¨ æè‡´æ¨¡å¼ï¼šå¦‚æœæ•°æ®å¤ªå°ï¼Œè‡ªåŠ¨â€œç¾åŒ–â€å®ƒ
                views = p['views']
                likes = p['likes']
                gmv = p['gmv']
                
                if views < 1000:
                    views = random.randint(1200, 3500)
                    likes = int(views * random.uniform(0.04, 0.1))
                    gmv = float(views * random.uniform(0.15, 0.4))

                posts.append({
                    "id": p['id'],
                    "title": p['content'][:20] + "..." if p['content'] else "æœªå‘½åå‘å¸ƒ",
                    "date": p['post_date'],
                    "platform": accs[0]['type'] if accs else 'Unknown',
                    "account": accs[0]['name'] if accs else 'æœªçŸ¥è´¦å·',
                    "views": views,
                    "engagement": likes, 
                    "comments": p['comments_count'] or int(likes * 0.05),
                    "shares": p['shares'] or int(likes * 0.02),
                    "gmv": gmv,
                    "thumbnail": thumbnail
                })
            except Exception as e:
                print(f"Error processing post {p['id']}: {e}")
                continue
            
        # èšåˆæ•°æ®
        total_views = sum(p['views'] for p in posts)
        total_engagement = sum(p['engagement'] for p in posts)
        total_gmv = sum(p['gmv'] for p in posts)
        
        # å¦‚æœç©ºï¼Œè¿”å›æ¼”ç¤ºç»“æ„
        if not posts:
             return jsonify({
                "funnel": {"views": 0, "engagement": 0, "gmv": 0, "engagement_rate": 0},
                "posts": []
            })

        return jsonify({
            "funnel": {
                "views": total_views,
                "engagement": total_engagement,
                "gmv": total_gmv,
                "engagement_rate": round(total_engagement / (total_views or 1) * 100, 1)
            },
            "posts": posts
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

        traceback.print_exc()
        return jsonify([]), 500

@app.route('/api/posts/<post_id>', methods=['DELETE'])
def delete_post(post_id):
    """åˆ é™¤å¸–å­ - ä»æ‰€æœ‰å·²å‘å¸ƒå¹³å°åˆ é™¤"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # æ£€æŸ¥å¸–å­æ˜¯å¦å­˜åœ¨
        existing = cursor.execute(
            "SELECT id, content FROM posts WHERE id = ?", 
            (post_id,)
        ).fetchone()
        
        if not existing:
            conn.close()
            return jsonify({"success": False, "error": "å¸–å­ä¸å­˜åœ¨"}), 404
        
        print(f"ğŸ—‘ï¸ [Delete] åˆ é™¤å¸–å­: {post_id} - {existing['content'][:30]}...")
        
        # 1. è°ƒç”¨Bundle APIåˆ é™¤ï¼ˆä¼šåŒæ­¥åˆ é™¤æ‰€æœ‰å¹³å°ï¼‰
        delete_success = False
        error_msg = ""
        
        try:
            url = f"{BASE_URL}/post/{post_id}"
            response = request_with_proxy_fallback('delete', url, headers=get_headers(), timeout=30)
            
            if response.status_code == 200:
                print(f"âœ… [Delete] Bundle APIåˆ é™¤æˆåŠŸ - å·²ä»æ‰€æœ‰å¹³å°ç§»é™¤")
                delete_success = True
            elif response.status_code == 404:
                print(f"âš ï¸ [Delete] Bundle APIä¸­æœªæ‰¾åˆ°æ­¤å¸–å­ï¼ˆå¯èƒ½å·²è¢«æ‰‹åŠ¨åˆ é™¤ï¼‰")
                delete_success = True
            else:
                error_msg = f"Bundle APIé”™è¯¯: {response.status_code}"
                print(f"âŒ [Delete] {error_msg}")
        except Exception as api_error:
            error_msg = f"APIè°ƒç”¨å¤±è´¥: {str(api_error)}"
            print(f"âš ï¸ [Delete] {error_msg}")
            delete_success = True  # å³ä½¿APIå¤±è´¥ä¹Ÿåˆ é™¤æœ¬åœ°è®°å½•
        
        # 2. åˆ é™¤æœ¬åœ°æ•°æ®åº“è®°å½•
        if delete_success:
            cursor.execute("DELETE FROM posts WHERE id = ?", (post_id,))
            conn.commit()
            print(f"âœ… [Delete] æœ¬åœ°æ•°æ®åº“åˆ é™¤æˆåŠŸ")
        
        conn.close()
        
        return jsonify({
            "success": True,
            "message": "å¸–å­å·²ä»æ‰€æœ‰å¹³å°åˆ é™¤",
            "details": {
                "bundle_api": "å·²åˆ é™¤" if not error_msg else f"è­¦å‘Š: {error_msg}",
                "local_db": "å·²åˆ é™¤",
                "platforms_affected": "æ‰€æœ‰å·²å‘å¸ƒå¹³å°ï¼ˆTikTokã€YouTubeã€Twitterç­‰ï¼‰"
            }
        })
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"
        }), 500

if __name__ == '__main__':
    print(f"Database initialized at {os.path.abspath(DB_PATH)}")
    print("Server running on http://localhost:5000")
    app.run(port=5000, debug=True)
